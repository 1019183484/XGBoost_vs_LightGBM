
{'num_leaves': 32, 'max_depth': 5, 'n_train': 500000}
training XGBoost
[00:22:06] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 12.449381351470947 seconds
[00:22:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 11.885575294494629 seconds
training LightGBM
LightGBM: 5.226647615432739 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.675223  0.675159
15   0.538657  0.538657  0.536850
30   0.489796  0.489796  0.487917
45   0.461254  0.461254  0.460996
60   0.443328  0.443328  0.443085
75   0.422786  0.422786  0.427510
90   0.407351  0.407351  0.416744
105  0.392894  0.392894  0.404913
120  0.385819  0.385819  0.393944
135  0.379876  0.379876  0.385745
150  0.373250  0.373250  0.378372
165  0.366858  0.366858  0.370963
180  0.361597  0.361597  0.363289
195  0.357106  0.357106  0.357302

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.675327  0.675282
15   0.540042  0.540042  0.538393
30   0.491851  0.491851  0.490047
45   0.463598  0.463598  0.463464
60   0.446067  0.446067  0.446023
75   0.426136  0.426136  0.430857
90   0.411187  0.411187  0.420516
105  0.397151  0.397151  0.409005
120  0.390497  0.390497  0.398496
135  0.384954  0.384954  0.390699
150  0.378667  0.378667  0.383539
165  0.372594  0.372594  0.376521
180  0.367742  0.367742  0.369207
195  0.363628  0.363628  0.363677

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         30        30   29
75         30        30   32
90         30        30   32
105        32        32   31
120        31        31   32
135        32        32   31
150        32        32   32
165        32        32   32
180        31        31   32
195        30        30   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125244  0.125244  0.139206
f1   0.077363  0.077363  0.043795
f7   0.073242  0.073242  0.098834
f17  0.070430  0.070430  0.055687
f5   0.068089  0.068089  0.054752


{'num_leaves': 32, 'max_depth': 10, 'n_train': 500000}
training XGBoost
[00:22:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 12.239546775817871 seconds
[00:22:48] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 11.773493528366089 seconds
training LightGBM
LightGBM: 6.004090785980225 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.507373  0.504056
30   0.489796  0.452641  0.450193
45   0.461254  0.424939  0.421044
60   0.441973  0.405291  0.400745
75   0.424671  0.389522  0.387223
90   0.409568  0.373764  0.376561
105  0.402111  0.363740  0.365810
120  0.391036  0.355245  0.356653
135  0.383902  0.347198  0.348178
150  0.375794  0.340875  0.340077
165  0.367041  0.334307  0.336314
180  0.362225  0.329864  0.331132
195  0.356370  0.322570  0.325978

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.508494  0.505676
30   0.491851  0.454354  0.452610
45   0.463598  0.427174  0.423845
60   0.444825  0.408179  0.404021
75   0.428041  0.393146  0.391019
90   0.413417  0.377977  0.380836
105  0.406221  0.368565  0.370526
120  0.395504  0.360624  0.361898
135  0.388673  0.353099  0.353956
150  0.381016  0.347152  0.346390
165  0.372565  0.341059  0.343069
180  0.368032  0.337215  0.338456
195  0.362488  0.330534  0.333815

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.127673  0.136560
f7   0.077845  0.064583  0.094765
f1   0.072288  0.069269  0.037269
f9   0.067771  0.071354  0.085388
f17  0.067761  0.063767  0.052060


{'num_leaves': 256, 'max_depth': 10, 'n_train': 500000}
training XGBoost
[00:23:06] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 30.786912441253662 seconds
[00:23:38] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 31.72959876060486 seconds
training LightGBM
LightGBM: 11.47434401512146 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.654859  0.655016
15   0.445656  0.412285  0.411963
30   0.386099  0.343984  0.345963
45   0.345863  0.314970  0.314964
60   0.324551  0.295087  0.297044
75   0.306972  0.278582  0.279776
90   0.294403  0.267757  0.265181
105  0.280862  0.259438  0.256810
120  0.270997  0.250853  0.247393
135  0.264641  0.242579  0.238975
150  0.255665  0.234124  0.231507
165  0.248372  0.225951  0.224825
180  0.239119  0.218516  0.218838
195  0.234054  0.214080  0.213493

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.655368  0.655577
15   0.449799  0.417807  0.417653
30   0.393282  0.353205  0.355185
45   0.355624  0.327243  0.326952
60   0.336659  0.310049  0.311699
75   0.321291  0.296213  0.297242
90   0.310871  0.287915  0.285630
105  0.299856  0.282387  0.279879
120  0.292293  0.276905  0.273601
135  0.288390  0.271804  0.268586
150  0.281990  0.266263  0.264450
165  0.277379  0.261208  0.261002
180  0.270612  0.256418  0.258079
195  0.268253  0.255184  0.255278

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  205
75        256       256  256
90        256       218  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       217  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.118651  0.113403  0.117106
f9   0.073339  0.066822  0.069162
f7   0.068624  0.064389  0.085848
f17  0.059297  0.055403  0.048813
f31  0.059139  0.067048  0.069502


{'num_leaves': 1024, 'max_depth': 10, 'n_train': 500000}
training XGBoost
[00:24:23] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 47.07355308532715 seconds
[00:25:10] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 46.869024991989136 seconds
training LightGBM
LightGBM: 14.326871633529663 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.651639  0.651639  0.651787
15   0.390788  0.390788  0.392943
30   0.324340  0.324340  0.321290
45   0.296892  0.296892  0.292872
60   0.274448  0.274448  0.275292
75   0.257760  0.257760  0.253256
90   0.244864  0.244864  0.239813
105  0.234966  0.234966  0.231397
120  0.223411  0.223411  0.219463
135  0.214793  0.214793  0.212184
150  0.208904  0.208904  0.204523
165  0.200966  0.200966  0.193077
180  0.194875  0.194875  0.184832
195  0.189971  0.189971  0.179449

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.652533  0.652533  0.652749
15   0.401175  0.401175  0.403284
30   0.340391  0.340391  0.337177
45   0.316944  0.316944  0.312927
60   0.298326  0.298326  0.298676
75   0.285349  0.285349  0.281720
90   0.276250  0.276250  0.271969
105  0.270693  0.270693  0.267390
120  0.263494  0.263494  0.260120
135  0.259340  0.259340  0.257021
150  0.257408  0.257408  0.253541
165  0.253312  0.253312  0.247345
180  0.250792  0.250792  0.244359
195  0.248831  0.248831  0.243347

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         852       852  844
15        745       745  787
30        521       521  507
45        413       413  550
60        723       723  324
75        172       172  796
90        342       342  500
105       302       302  150
120       759       759  333
135       373       373  501
150       399       399  816
165       400       400  548
180       578       578  418
195       249       249  450

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.115447  0.115447  0.112753
f9   0.068445  0.068445  0.067044
f7   0.063394  0.063394  0.082829
f31  0.063055  0.063055  0.069558
f10  0.057661  0.057661  0.092848


{'num_leaves': 32, 'max_depth': 15, 'n_train': 500000}
training XGBoost
[00:26:16] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 11.97623586654663 seconds
[00:26:28] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 11.908467292785645 seconds
training LightGBM
LightGBM: 6.283178329467773 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.504339  0.505071
30   0.489796  0.448982  0.449470
45   0.461254  0.419500  0.418257
60   0.441973  0.399314  0.397380
75   0.424671  0.384352  0.380460
90   0.409568  0.371749  0.368609
105  0.402111  0.360344  0.359724
120  0.391036  0.349898  0.351468
135  0.383902  0.342412  0.342732
150  0.375794  0.336676  0.335642
165  0.367041  0.332410  0.329198
180  0.362225  0.326543  0.323556
195  0.356370  0.321183  0.318037

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.505683  0.506502
30   0.491851  0.450852  0.451511
45   0.463598  0.421869  0.420962
60   0.444825  0.402349  0.400770
75   0.428041  0.388088  0.384485
90   0.413417  0.376058  0.373277
105  0.406221  0.365294  0.364934
120  0.395504  0.355332  0.357278
135  0.388673  0.348370  0.349151
150  0.381016  0.343221  0.342505
165  0.372565  0.339496  0.336528
180  0.368032  0.334133  0.331519
195  0.362488  0.329340  0.326478

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.126979  0.136217
f7   0.077845  0.066851  0.091529
f1   0.072288  0.081684  0.038298
f9   0.067771  0.071102  0.083204
f17  0.067761  0.065601  0.050563


{'num_leaves': 256, 'max_depth': 15, 'n_train': 500000}
training XGBoost
[00:26:46] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 31.074125051498413 seconds
[00:27:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 30.739781379699707 seconds
training LightGBM
LightGBM: 11.503187417984009 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.653653  0.653966
15   0.445656  0.396437  0.397702
30   0.386099  0.319544  0.323089
45   0.345863  0.290004  0.292334
60   0.324551  0.271027  0.274777
75   0.307560  0.257728  0.259717
90   0.293811  0.246880  0.250524
105  0.281713  0.240516  0.244159
120  0.270883  0.234158  0.238195
135  0.260389  0.229712  0.232565
150  0.251743  0.222241  0.228049
165  0.244601  0.215327  0.218883
180  0.239018  0.210774  0.213127
195  0.234650  0.206706  0.208882

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.654242  0.654562
15   0.449799  0.402374  0.404126
30   0.393282  0.329378  0.332842
45   0.355624  0.303014  0.305400
60   0.336659  0.287085  0.290906
75   0.321924  0.277238  0.279335
90   0.310479  0.269961  0.273815
105  0.300796  0.267413  0.270970
120  0.292384  0.264856  0.268420
135  0.284450  0.264075  0.266285
150  0.278564  0.259935  0.265198
165  0.274273  0.256133  0.259088
180  0.271338  0.255453  0.256705
195  0.269654  0.254698  0.255760

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.119129  0.113184  0.114545
f9   0.072751  0.068910  0.069879
f7   0.069169  0.062379  0.084403
f10  0.059257  0.058302  0.094745
f17  0.058706  0.051032  0.048781


{'num_leaves': 1024, 'max_depth': 15, 'n_train': 500000}
training XGBoost
[00:28:02] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 79.00461864471436 seconds
[00:29:22] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 80.83007717132568 seconds
training LightGBM
LightGBM: 21.98438286781311 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650728  0.643126  0.643179
15   0.381140  0.336316  0.336360
30   0.305366  0.252789  0.253922
45   0.266276  0.218436  0.219400
60   0.239462  0.201520  0.201049
75   0.220427  0.184453  0.186899
90   0.202603  0.173328  0.173162
105  0.191875  0.161192  0.162216
120  0.180153  0.149300  0.150966
135  0.167028  0.139448  0.140027
150  0.157270  0.131558  0.130374
165  0.149207  0.122681  0.121893
180  0.141134  0.114982  0.113722
195  0.132256  0.107239  0.106911

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651801  0.644820  0.644782
15   0.393680  0.353735  0.353742
30   0.326315  0.282074  0.283002
45   0.294495  0.258017  0.258783
60   0.274747  0.249367  0.248672
75   0.262881  0.242585  0.244101
90   0.253732  0.240142  0.240588
105  0.250122  0.236741  0.238337
120  0.246481  0.233530  0.235141
135  0.241153  0.231894  0.232236
150  0.238898  0.230694  0.230141
165  0.237557  0.229376  0.229201
180  0.235415  0.228396  0.227815
195  0.232610  0.227252  0.226842

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024       817  1024
75       1024      1024  1024
90       1024      1024   659
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165       629      1024  1024
180      1024      1024   573
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.104525  0.099508  0.104424
f9   0.065486  0.063380  0.061893
f7   0.063335  0.059417  0.073818
f31  0.063033  0.064322  0.069396
f10  0.058011  0.057214  0.088218


{'num_leaves': 4096, 'max_depth': 15, 'n_train': 500000}
training XGBoost
[00:31:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 143.09397172927856 seconds
[00:33:38] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 143.9469699859619 seconds
training LightGBM
LightGBM: 35.284117460250854 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.638249  0.635119  0.635122
15   0.304004  0.287983  0.287461
30   0.210452  0.192443  0.193864
45   0.178598  0.161888  0.161640
60   0.161279  0.149479  0.149547
75   0.144680  0.133556  0.135945
90   0.131739  0.119178  0.123650
105  0.118691  0.106468  0.113591
120  0.104918  0.096595  0.100849
135  0.095043  0.087608  0.089675
150  0.086893  0.079124  0.083026
165  0.078863  0.072085  0.074580
180  0.071321  0.067092  0.068500
195  0.065756  0.059248  0.063122

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.641995  0.639688  0.639394
15   0.342940  0.332860  0.332462
30   0.272719  0.263850  0.264326
45   0.252559  0.245412  0.244684
60   0.243413  0.239214  0.238880
75   0.237795  0.232962  0.235305
90   0.234783  0.229043  0.232013
105  0.232045  0.226292  0.229820
120  0.229127  0.225153  0.227006
135  0.227567  0.224299  0.224769
150  0.225802  0.222758  0.224008
165  0.224652  0.221945  0.222659
180  0.224101  0.221395  0.221912
195  0.223289  0.220479  0.221522

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       3185      3649  3452
45       1699      2252  2891
60       1362       978  1391
75        430       584  3274
90       4096       516  1044
105      1926      1621  1317
120      3266       565  2591
135      4096      2373  1900
150      4096       558  3006
165       801      2429   774
180      3162       909  1612
195       762      3391   508

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.097489  0.096947  0.101085
f9   0.062846  0.061169  0.060428
f31  0.061997  0.062953  0.070731
f7   0.057490  0.057339  0.070512
f10  0.055121  0.054940  0.082614


{'num_leaves': 32, 'max_depth': 20, 'n_train': 500000}
training XGBoost
[00:36:54] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 12.108218908309937 seconds
[00:37:06] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 11.618001699447632 seconds
training LightGBM
LightGBM: 6.096652984619141 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.504339  0.505071
30   0.489796  0.448949  0.447672
45   0.461254  0.420841  0.419927
60   0.441973  0.402737  0.400765
75   0.424671  0.389002  0.383045
90   0.409568  0.375777  0.371528
105  0.402111  0.365269  0.361442
120  0.391036  0.357292  0.355231
135  0.383902  0.349877  0.348110
150  0.375794  0.342334  0.342293
165  0.367041  0.334894  0.335972
180  0.362225  0.328755  0.330748
195  0.356370  0.323611  0.325765

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.505683  0.506502
30   0.491851  0.450813  0.449614
45   0.463598  0.423050  0.422468
60   0.444825  0.405542  0.403883
75   0.428041  0.392532  0.386883
90   0.413417  0.379991  0.375897
105  0.406221  0.370130  0.366401
120  0.395504  0.362799  0.360631
135  0.388673  0.355917  0.353985
150  0.381016  0.348882  0.348559
165  0.372565  0.342056  0.342742
180  0.368032  0.336465  0.338064
195  0.362488  0.331837  0.333689

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.125244  0.137626
f7   0.077845  0.064981  0.089094
f1   0.072288  0.077573  0.038883
f9   0.067771  0.069495  0.087749
f17  0.067761  0.068597  0.049599


{'num_leaves': 256, 'max_depth': 20, 'n_train': 500000}
training XGBoost
[00:37:24] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 31.53250241279602 seconds
[00:37:56] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 30.401161909103394 seconds
training LightGBM
LightGBM: 11.794371843338013 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.653653  0.653966
15   0.445656  0.395474  0.396297
30   0.386099  0.317459  0.318905
45   0.345863  0.283433  0.284111
60   0.324551  0.263905  0.263636
75   0.307560  0.253387  0.253100
90   0.293811  0.245690  0.246459
105  0.281713  0.239653  0.238939
120  0.270883  0.233274  0.232942
135  0.260389  0.227804  0.227143
150  0.251743  0.222555  0.220927
165  0.244601  0.216768  0.214362
180  0.239018  0.211587  0.209370
195  0.234650  0.205142  0.203138

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.654242  0.654562
15   0.449799  0.401607  0.402703
30   0.393282  0.327482  0.328881
45   0.355624  0.296832  0.297446
60   0.336659  0.280721  0.280329
75   0.321924  0.273877  0.273566
90   0.310479  0.270201  0.270761
105  0.300796  0.267648  0.266858
120  0.292384  0.264845  0.264179
135  0.284450  0.262830  0.261840
150  0.278564  0.260868  0.258811
165  0.274273  0.257775  0.255570
180  0.271338  0.255507  0.253980
195  0.269654  0.252207  0.250770

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.119129  0.113740  0.113617
f9   0.072751  0.070219  0.069512
f7   0.069169  0.061658  0.083999
f10  0.059257  0.057785  0.095079
f17  0.058706  0.052120  0.048212


{'num_leaves': 1024, 'max_depth': 20, 'n_train': 500000}
training XGBoost
[00:38:40] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 80.28190755844116 seconds
[00:40:01] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 83.79851698875427 seconds
training LightGBM
LightGBM: 24.19647765159607 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650728  0.642855  0.642935
15   0.381140  0.332252  0.331822
30   0.305366  0.246955  0.246637
45   0.266276  0.211213  0.208533
60   0.239386  0.189230  0.186298
75   0.219788  0.174473  0.171477
90   0.205906  0.161722  0.158182
105  0.192419  0.150549  0.145442
120  0.178247  0.139181  0.135364
135  0.166934  0.129020  0.125568
150  0.156319  0.119037  0.116261
165  0.147519  0.110326  0.108521
180  0.138963  0.102022  0.100627
195  0.131748  0.094655  0.093798

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651801  0.644539  0.644562
15   0.393680  0.350114  0.349590
30   0.326315  0.277369  0.276677
45   0.294495  0.252317  0.249895
60   0.274656  0.242146  0.238810
75   0.262760  0.238951  0.235687
90   0.257027  0.236805  0.233644
105  0.251768  0.234775  0.230464
120  0.244885  0.231833  0.229434
135  0.240849  0.230303  0.227628
150  0.236798  0.228482  0.226249
165  0.234899  0.227174  0.225573
180  0.232987  0.225811  0.224262
195  0.231599  0.224417  0.223351

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.107149  0.100070  0.102359
f9   0.065546  0.064279  0.061285
f7   0.063039  0.058672  0.075125
f31  0.061679  0.062504  0.067027
f10  0.058114  0.055391  0.088461


{'num_leaves': 4096, 'max_depth': 20, 'n_train': 500000}
training XGBoost
[00:41:57] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 205.711172580719 seconds
[00:45:27] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 210.26244592666626 seconds
training LightGBM
LightGBM: 52.82212018966675 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.638249  0.632386  0.632352
15   0.304004  0.263888  0.264590
30   0.208051  0.162379  0.162841
45   0.159551  0.120920  0.118853
60   0.139336  0.104461  0.102170
75   0.118094  0.089495  0.089318
90   0.098598  0.073592  0.076502
105  0.082876  0.060150  0.063258
120  0.068826  0.048534  0.051748
135  0.057697  0.038929  0.042693
150  0.046681  0.033873  0.033836
165  0.038105  0.026152  0.027824
180  0.032757  0.021129  0.022393
195  0.028061  0.017894  0.018855

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.641995  0.637384  0.637230
15   0.342940  0.317612  0.317858
30   0.271828  0.249819  0.250408
45   0.244324  0.230677  0.230381
60   0.235702  0.225052  0.225158
75   0.230296  0.222071  0.223451
90   0.226332  0.219748  0.220785
105  0.224279  0.217470  0.219285
120  0.222867  0.216145  0.217747
135  0.221517  0.215538  0.217128
150  0.220004  0.215756  0.216838
165  0.219737  0.216183  0.217366
180  0.219869  0.217151  0.218208
195  0.220236  0.218472  0.219485

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      2562  4096
60       3032      4096   995
75       4096      2808  1417
90       4096      4096  2443
105      2116      4096  3981
120      4096      3098  4096
135      3236      3948  2798
150      3550      2263  4096
165      2794      4096  2310
180      3912      4096  4096
195      1363      3579  1541

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.094020  0.094717  0.096635
f31  0.062246  0.064052  0.067339
f9   0.062123  0.061928  0.057588
f7   0.057860  0.056893  0.069280
f10  0.055850  0.055396  0.081935


{'num_leaves': 32, 'max_depth': 5, 'n_train': 1000000}
training XGBoost
[00:50:19] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 22.5862398147583 seconds
[00:50:42] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 22.192341089248657 seconds
training LightGBM
LightGBM: 10.846415996551514 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.670712  0.670690
15   0.519764  0.519764  0.517547
30   0.465616  0.465616  0.462235
45   0.437321  0.437321  0.435981
60   0.416064  0.416064  0.415267
75   0.401604  0.401604  0.399342
90   0.387141  0.387141  0.386791
105  0.377943  0.377943  0.377562
120  0.371751  0.371751  0.371134
135  0.363106  0.363106  0.362164
150  0.356368  0.356368  0.355716
165  0.351519  0.351519  0.350397
180  0.344373  0.344373  0.344984
195  0.338864  0.338864  0.340146

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.670815  0.670768
15   0.520467  0.520467  0.518067
30   0.466785  0.466785  0.463390
45   0.439002  0.439002  0.437522
60   0.418094  0.418094  0.417141
75   0.403941  0.403941  0.401528
90   0.389714  0.389714  0.389355
105  0.380822  0.380822  0.380342
120  0.374910  0.374910  0.374079
135  0.366469  0.366469  0.365226
150  0.360049  0.360049  0.359005
165  0.355397  0.355397  0.353831
180  0.348419  0.348419  0.348625
195  0.343219  0.343219  0.343988

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         29        29   32
105        32        32   32
120        32        32   32
135        31        31   32
150        32        32   32
165        29        29   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.141327  0.141327  0.134151
f15  0.127395  0.127395  0.119172
f26  0.086050  0.086050  0.082649
f27  0.082321  0.082321  0.075474
f12  0.070329  0.070329  0.061019


{'num_leaves': 32, 'max_depth': 10, 'n_train': 1000000}
training XGBoost
[00:51:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 22.038646459579468 seconds
[00:51:38] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 21.171558380126953 seconds
training LightGBM
LightGBM: 13.011224746704102 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.498551  0.498702
30   0.465616  0.435091  0.435797
45   0.437321  0.404291  0.402613
60   0.416064  0.383384  0.382852
75   0.401602  0.366779  0.366588
90   0.387134  0.356035  0.356626
105  0.376121  0.347044  0.346900
120  0.368930  0.339186  0.340142
135  0.361933  0.332896  0.333221
150  0.357223  0.327741  0.327381
165  0.349977  0.322623  0.322336
180  0.344920  0.318604  0.316594
195  0.339195  0.313570  0.311414

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.499141  0.499510
30   0.466785  0.436483  0.437333
45   0.439002  0.406118  0.404662
60   0.418094  0.385431  0.385206
75   0.403939  0.369090  0.369147
90   0.389707  0.358722  0.359459
105  0.379062  0.349946  0.349918
120  0.372137  0.342284  0.343417
135  0.365405  0.336256  0.336673
150  0.360922  0.331347  0.331072
165  0.353928  0.326432  0.326268
180  0.349107  0.322587  0.320845
195  0.343517  0.317807  0.315849

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.126506  0.118833
f15  0.122935  0.108628  0.105144
f26  0.090022  0.080820  0.083973
f27  0.086085  0.107656  0.071126
f12  0.068082  0.078310  0.059453


{'num_leaves': 256, 'max_depth': 10, 'n_train': 1000000}
training XGBoost
[00:52:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 44.947270154953 seconds
[00:52:58] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 45.643410444259644 seconds
training LightGBM
LightGBM: 22.674606800079346 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.654731  0.654782
15   0.436275  0.409136  0.407353
30   0.364068  0.335276  0.332471
45   0.330131  0.300765  0.301992
60   0.309972  0.284512  0.285799
75   0.294529  0.270522  0.271131
90   0.285495  0.258248  0.257753
105  0.274485  0.247846  0.247697
120  0.267220  0.240443  0.241119
135  0.258687  0.233898  0.232676
150  0.250579  0.228270  0.227312
165  0.245805  0.222656  0.223417
180  0.238242  0.218731  0.219868
195  0.231710  0.215134  0.216105

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.655093  0.655152
15   0.439298  0.412880  0.410991
30   0.369188  0.341609  0.338589
45   0.336710  0.308982  0.309876
60   0.317876  0.294392  0.295135
75   0.303677  0.281850  0.281958
90   0.295721  0.271192  0.270131
105  0.285901  0.262132  0.261600
120  0.279843  0.256325  0.256700
135  0.272573  0.251479  0.249916
150  0.265802  0.247573  0.246271
165  0.262552  0.243432  0.243981
180  0.256215  0.241342  0.242365
195  0.251042  0.239506  0.240504

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110276  0.106002  0.094652
f23  0.109606  0.109734  0.106658
f27  0.092350  0.090317  0.057798
f26  0.078407  0.072730  0.074652
f12  0.066186  0.065171  0.052246


{'num_leaves': 1024, 'max_depth': 10, 'n_train': 1000000}
training XGBoost
[00:54:08] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 72.16544151306152 seconds
[00:55:21] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 71.04157280921936 seconds
training LightGBM
LightGBM: 27.233805656433105 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.651142  0.651142  0.651270
15   0.383524  0.383524  0.383772
30   0.308016  0.308016  0.307161
45   0.274393  0.274393  0.275278
60   0.258309  0.258309  0.258143
75   0.246340  0.246340  0.244057
90   0.234777  0.234777  0.232616
105  0.225060  0.225060  0.224078
120  0.217585  0.217585  0.217155
135  0.210084  0.210084  0.209402
150  0.200119  0.200119  0.204945
165  0.194310  0.194310  0.197544
180  0.191428  0.191428  0.193443
195  0.186787  0.186787  0.188460

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651907  0.651907  0.652048
15   0.391024  0.391024  0.391356
30   0.320003  0.320003  0.319647
45   0.289681  0.289681  0.290851
60   0.275817  0.275817  0.275987
75   0.265776  0.265776  0.264297
90   0.256561  0.256561  0.255231
105  0.249292  0.249292  0.249357
120  0.244795  0.244795  0.244988
135  0.239420  0.239420  0.240081
150  0.232710  0.232710  0.237818
165  0.229940  0.229940  0.233350
180  0.229551  0.229551  0.231826
195  0.227608  0.227608  0.229374

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         921       921  929
15        887       887  957
30        853       853  845
45        605       605  634
60        606       606  497
75        807       807  628
90        524       524  535
105       340       340  468
120       704       704  580
135       248       248  462
150       422       422  744
165       749       749  691
180       232       232  528
195       567       567  638

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.105729  0.105729  0.104315
f15  0.102879  0.102879  0.094698
f27  0.085082  0.085082  0.057278
f26  0.074980  0.074980  0.070339
f12  0.061103  0.061103  0.051727


{'num_leaves': 32, 'max_depth': 15, 'n_train': 1000000}
training XGBoost
[00:57:04] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 21.81158685684204 seconds
[00:57:26] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 21.661242723464966 seconds
training LightGBM
LightGBM: 12.958455562591553 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.497579  0.498695
30   0.465616  0.433017  0.436759
45   0.437321  0.400551  0.405310
60   0.416064  0.379374  0.384706
75   0.401602  0.367048  0.369787
90   0.387134  0.355086  0.358808
105  0.376121  0.345083  0.347798
120  0.368930  0.337904  0.340338
135  0.361933  0.330417  0.331772
150  0.357223  0.323761  0.324435
165  0.349977  0.317371  0.318875
180  0.344920  0.312428  0.314737
195  0.339195  0.308345  0.310399

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.498277  0.499392
30   0.466785  0.434389  0.438104
45   0.439002  0.402278  0.406981
60   0.418094  0.381363  0.386806
75   0.403939  0.369384  0.372112
90   0.389707  0.357700  0.361414
105  0.379062  0.347979  0.350778
120  0.372137  0.341029  0.343688
135  0.365405  0.333855  0.335382
150  0.360922  0.327532  0.328219
165  0.353928  0.321444  0.322906
180  0.349107  0.316756  0.318998
195  0.343517  0.312857  0.314917

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.127693  0.119828
f15  0.122935  0.116502  0.106557
f26  0.090022  0.078011  0.083026
f27  0.086085  0.098919  0.072917
f12  0.068082  0.082346  0.058643


{'num_leaves': 256, 'max_depth': 15, 'n_train': 1000000}
training XGBoost
[00:58:01] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 43.956422567367554 seconds
[00:58:46] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 44.7257022857666 seconds
training LightGBM
LightGBM: 22.65332531929016 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.653759  0.653882
15   0.436275  0.397689  0.397984
30   0.364068  0.319342  0.320136
45   0.330131  0.283043  0.284247
60   0.309972  0.265661  0.266184
75   0.294529  0.251078  0.251481
90   0.285495  0.242280  0.241609
105  0.274485  0.234119  0.236488
120  0.267220  0.227768  0.229365
135  0.258687  0.222479  0.225269
150  0.250579  0.218504  0.220956
165  0.245804  0.214100  0.216640
180  0.239562  0.210428  0.211856
195  0.233704  0.206175  0.208866

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.654160  0.654291
15   0.439298  0.401931  0.402092
30   0.369188  0.325920  0.326806
45   0.336710  0.291684  0.292814
60   0.317876  0.276088  0.276493
75   0.303677  0.263207  0.263423
90   0.295721  0.256162  0.255162
105  0.285901  0.249801  0.252053
120  0.279843  0.245363  0.246673
135  0.272573  0.242046  0.244567
150  0.265802  0.240092  0.242143
165  0.262552  0.237629  0.239823
180  0.257501  0.235894  0.236835
195  0.253013  0.233382  0.235682

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110624  0.106874  0.096248
f23  0.110058  0.106224  0.106597
f27  0.091593  0.087996  0.059252
f26  0.078340  0.069725  0.071416
f12  0.067197  0.063833  0.049449


{'num_leaves': 1024, 'max_depth': 15, 'n_train': 1000000}
training XGBoost
[00:59:55] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 99.38925647735596 seconds
[01:01:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 102.54871034622192 seconds
training LightGBM
LightGBM: 37.50640153884888 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650549  0.643973  0.643954
15   0.379917  0.338724  0.339882
30   0.301987  0.258629  0.259099
45   0.263452  0.222105  0.223123
60   0.243268  0.206296  0.203529
75   0.227790  0.192565  0.192006
90   0.212702  0.181020  0.180344
105  0.202582  0.171697  0.169099
120  0.194347  0.164250  0.160174
135  0.185765  0.156942  0.153828
150  0.176819  0.150650  0.147376
165  0.170091  0.144355  0.140949
180  0.164323  0.138118  0.134671
195  0.157533  0.131431  0.129470

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651348  0.644941  0.644960
15   0.388126  0.349592  0.350832
30   0.315416  0.276035  0.276559
45   0.281390  0.245225  0.246499
60   0.264951  0.234128  0.232075
75   0.253319  0.226688  0.226859
90   0.242329  0.221518  0.221547
105  0.237006  0.218643  0.216613
120  0.233330  0.217450  0.213708
135  0.229333  0.216016  0.213342
150  0.224727  0.214817  0.212312
165  0.222586  0.213605  0.211028
180  0.221037  0.212242  0.209915
195  0.218470  0.210152  0.209038

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024       988  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.099805  0.104039  0.097005
f15  0.097814  0.097895  0.089892
f27  0.080228  0.076397  0.054279
f26  0.071959  0.066414  0.063344
f12  0.059452  0.058369  0.051050


{'num_leaves': 4096, 'max_depth': 15, 'n_train': 1000000}
training XGBoost
[01:04:04] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 210.01424980163574 seconds
[01:07:37] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 207.14068627357483 seconds
training LightGBM
LightGBM: 62.29611301422119 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.640997  0.636590  0.636563
15   0.317563  0.291948  0.291205
30   0.229187  0.202548  0.203156
45   0.185212  0.164273  0.164330
60   0.167143  0.148091  0.146720
75   0.152685  0.131793  0.132551
90   0.137441  0.122523  0.122828
105  0.127334  0.112892  0.112503
120  0.114207  0.104450  0.102809
135  0.107067  0.096897  0.095732
150  0.099984  0.090378  0.090255
165  0.094205  0.083945  0.083945
180  0.086768  0.078155  0.077053
195  0.078581  0.071887  0.071942

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.643100  0.639137  0.639141
15   0.340330  0.319891  0.319258
30   0.266388  0.248607  0.249178
45   0.235921  0.225026  0.225182
60   0.225254  0.216929  0.215855
75   0.219214  0.211246  0.211314
90   0.214868  0.209586  0.209260
105  0.212827  0.207766  0.207375
120  0.209304  0.206494  0.205317
135  0.208288  0.205194  0.204242
150  0.207166  0.203853  0.203700
165  0.206298  0.202952  0.202617
180  0.204836  0.202244  0.201940
195  0.203333  0.201211  0.201227

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       1158      1079  1794
75       4096      2594  3990
90       4096      4096  1446
105      1882      3973  4096
120       943      1552  2348
135      4096      1647  3131
150      2023       788  1393
165      1275      2553  3521
180      3169      3298  1186
195      3639      1608  1551

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.092808  0.096417  0.092937
f15  0.090187  0.090334  0.083716
f27  0.071361  0.070850  0.051746
f26  0.063860  0.062841  0.059505
f31  0.058116  0.056992  0.074601


{'num_leaves': 32, 'max_depth': 20, 'n_train': 1000000}
training XGBoost
[01:12:29] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 21.71352243423462 seconds
[01:12:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 21.838057041168213 seconds
training LightGBM
LightGBM: 13.109389066696167 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.497579  0.498695
30   0.465616  0.433017  0.436759
45   0.437321  0.400551  0.405310
60   0.416064  0.379374  0.384198
75   0.401602  0.366446  0.368489
90   0.387134  0.356462  0.357139
105  0.376121  0.347640  0.347525
120  0.368930  0.339436  0.340291
135  0.361933  0.331315  0.333814
150  0.357223  0.324844  0.326401
165  0.349977  0.318642  0.319250
180  0.344920  0.313780  0.314687
195  0.339195  0.308742  0.309682

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.498277  0.499392
30   0.466785  0.434389  0.438104
45   0.439002  0.402278  0.406981
60   0.418094  0.381363  0.386366
75   0.403939  0.368830  0.371027
90   0.389707  0.359072  0.359909
105  0.379062  0.350503  0.350525
120  0.372137  0.342583  0.343529
135  0.365405  0.334745  0.337299
150  0.360922  0.328601  0.330175
165  0.353928  0.322562  0.323401
180  0.349107  0.317854  0.319035
195  0.343517  0.313083  0.314244

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.125048  0.119417
f15  0.122935  0.111027  0.105055
f26  0.090022  0.079951  0.084381
f27  0.086085  0.099465  0.072204
f12  0.068082  0.084838  0.059524


{'num_leaves': 256, 'max_depth': 20, 'n_train': 1000000}
training XGBoost
[01:13:27] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 45.021310567855835 seconds
[01:14:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 47.905537128448486 seconds
training LightGBM
LightGBM: 23.275856733322144 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.653759  0.653882
15   0.436275  0.397949  0.398429
30   0.364068  0.319321  0.319392
45   0.330131  0.280924  0.282460
60   0.309972  0.260308  0.260581
75   0.294529  0.246195  0.246320
90   0.285495  0.238251  0.237399
105  0.274485  0.231892  0.231755
120  0.267220  0.225970  0.226808
135  0.258687  0.221754  0.221183
150  0.250579  0.216947  0.217474
165  0.245804  0.212677  0.213359
180  0.239562  0.207560  0.208842
195  0.233704  0.204132  0.205788

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.654160  0.654291
15   0.439298  0.402164  0.402700
30   0.369188  0.326011  0.326226
45   0.336710  0.289500  0.291343
60   0.317876  0.270695  0.271149
75   0.303677  0.258203  0.258529
90   0.295721  0.252180  0.251366
105  0.285901  0.247836  0.247761
120  0.279843  0.243872  0.244766
135  0.272573  0.241625  0.240910
150  0.265802  0.238649  0.239234
165  0.262552  0.236353  0.237079
180  0.257501  0.232988  0.234332
195  0.253013  0.231363  0.233252

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110624  0.106380  0.097308
f23  0.110058  0.110898  0.106229
f27  0.091593  0.084986  0.057826
f26  0.078340  0.070899  0.072413
f12  0.067197  0.061171  0.049530


{'num_leaves': 1024, 'max_depth': 20, 'n_train': 1000000}
training XGBoost
[01:15:25] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 100.84623432159424 seconds
[01:17:07] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 101.03940629959106 seconds
training LightGBM
LightGBM: 37.31529116630554 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650549  0.643458  0.643552
15   0.379917  0.337132  0.336633
30   0.301987  0.254547  0.254079
45   0.263452  0.216717  0.217000
60   0.243268  0.196326  0.196308
75   0.227790  0.183981  0.183190
90   0.212702  0.173867  0.173372
105  0.202536  0.164521  0.165280
120  0.194374  0.156230  0.157161
135  0.185182  0.149129  0.149883
150  0.176199  0.142146  0.142416
165  0.168494  0.135063  0.135690
180  0.161549  0.128477  0.129528
195  0.155590  0.123057  0.123928

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651348  0.644455  0.644528
15   0.388126  0.348313  0.347765
30   0.315416  0.272545  0.272157
45   0.281390  0.240839  0.241094
60   0.264951  0.226687  0.226532
75   0.253319  0.221760  0.220860
90   0.242329  0.218880  0.218523
105  0.236956  0.216367  0.216658
120  0.233646  0.214229  0.214526
135  0.228747  0.212977  0.213260
150  0.224112  0.211425  0.211312
165  0.221090  0.209543  0.210437
180  0.218330  0.208676  0.209740
195  0.216394  0.208059  0.208931

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.098998  0.103551  0.095200
f15  0.098559  0.098764  0.090630
f27  0.079820  0.074899  0.053327
f26  0.071173  0.063356  0.063990
f12  0.059594  0.056441  0.051201


{'num_leaves': 4096, 'max_depth': 20, 'n_train': 1000000}
training XGBoost
[01:19:34] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 261.8594284057617 seconds
[01:24:00] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 285.8771333694458 seconds
training LightGBM
LightGBM: 88.69690918922424 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.640997  0.633776  0.633688
15   0.317563  0.277907  0.277799
30   0.229187  0.185827  0.185617
45   0.185212  0.143685  0.144285
60   0.157450  0.119812  0.119694
75   0.139900  0.103525  0.102177
90   0.124637  0.089445  0.089191
105  0.109539  0.077772  0.076876
120  0.097830  0.067224  0.065761
135  0.087289  0.059082  0.055118
150  0.078557  0.050006  0.047240
165  0.070313  0.042528  0.040429
180  0.062024  0.035838  0.034773
195  0.056294  0.030475  0.030100

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.643100  0.636476  0.636474
15   0.340330  0.308290  0.308098
30   0.266388  0.237060  0.236783
45   0.235921  0.214238  0.214665
60   0.220722  0.206273  0.205841
75   0.215195  0.203469  0.202815
90   0.211442  0.201209  0.201278
105  0.207278  0.199788  0.199458
120  0.204773  0.198383  0.198546
135  0.203375  0.197834  0.197295
150  0.202547  0.197355  0.197103
165  0.201730  0.197240  0.196934
180  0.201061  0.197419  0.197135
195  0.200473  0.198022  0.197806

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      3702  4096
75       4096      3173  4096
90       4096      2853  4096
105      4096      3091  4096
120      4096      4096  4096
135      2935      4096  2178
150      2664      4096  4096
165      3486      4096  4096
180      4096      4096  4096
195      4096      4096  4096

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.089533  0.093178  0.089484
f15  0.088024  0.089299  0.081605
f27  0.069919  0.066631  0.050692
f26  0.062530  0.061258  0.057823
f31  0.058298  0.057023  0.072854


{'num_leaves': 32, 'max_depth': 5, 'n_train': 2000000}
training XGBoost
[01:30:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 41.090778827667236 seconds
[01:31:32] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 40.009100914001465 seconds
training LightGBM
LightGBM: 22.496177434921265 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.668197  0.668792
15   0.502499  0.502499  0.504351
30   0.458417  0.458417  0.460120
45   0.428591  0.428591  0.431825
60   0.412420  0.412420  0.413065
75   0.397671  0.397671  0.395972
90   0.387534  0.387534  0.383286
105  0.378149  0.378149  0.374027
120  0.372052  0.372052  0.365721
135  0.363631  0.363631  0.359936
150  0.356775  0.356775  0.351934
165  0.351817  0.351817  0.347529
180  0.342262  0.342262  0.339184
195  0.337286  0.337286  0.332808

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.668257  0.668860
15   0.503355  0.503355  0.505316
30   0.459662  0.459662  0.461592
45   0.430273  0.430273  0.433632
60   0.414352  0.414352  0.415190
75   0.399917  0.399917  0.398316
90   0.389928  0.389928  0.385778
105  0.380722  0.380722  0.376646
120  0.374797  0.374797  0.368496
135  0.366580  0.366580  0.362844
150  0.359827  0.359827  0.354928
165  0.354992  0.354992  0.350621
180  0.345515  0.345515  0.342442
195  0.340667  0.340667  0.336205

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         31        31   32
90         27        27   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.130517  0.130517  0.116585
f29  0.094960  0.094960  0.097067
f16  0.086271  0.086271  0.081918
f31  0.080593  0.080593  0.036486
f12  0.069270  0.069270  0.059917


{'num_leaves': 32, 'max_depth': 10, 'n_train': 2000000}
training XGBoost
[01:32:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 39.93000674247742 seconds
[01:33:16] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 38.94495987892151 seconds
training LightGBM
LightGBM: 25.768223524093628 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492801  0.492586
30   0.458417  0.435045  0.433973
45   0.428591  0.402957  0.403211
60   0.412332  0.382094  0.382484
75   0.397652  0.370901  0.368490
90   0.387497  0.361233  0.356052
105  0.378310  0.350306  0.347458
120  0.368572  0.339882  0.338753
135  0.360008  0.331246  0.331536
150  0.353769  0.324822  0.325243
165  0.349606  0.319309  0.317694
180  0.344543  0.314639  0.312886
195  0.337779  0.311072  0.307084

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493941  0.493720
30   0.459662  0.436595  0.435456
45   0.430273  0.404880  0.405039
60   0.414270  0.384326  0.384516
75   0.399854  0.373299  0.370750
90   0.389975  0.363858  0.358529
105  0.381044  0.353100  0.350085
120  0.371437  0.342698  0.341536
135  0.362940  0.334214  0.334439
150  0.356809  0.327931  0.328246
165  0.352735  0.322511  0.320871
180  0.347761  0.318004  0.316148
195  0.341143  0.314555  0.310520

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.138336  0.111883
f29  0.096980  0.096677  0.096881
f16  0.087717  0.102263  0.086651
f31  0.074015  0.075692  0.037116
f12  0.066929  0.065681  0.061936


{'num_leaves': 256, 'max_depth': 10, 'n_train': 2000000}
training XGBoost
[01:34:22] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 74.23485398292542 seconds
[01:35:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 76.62652850151062 seconds
training LightGBM
LightGBM: 46.65864539146423 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652710  0.651779
15   0.416301  0.395077  0.394060
30   0.351350  0.320231  0.322351
45   0.323185  0.296724  0.296705
60   0.307805  0.279908  0.277630
75   0.297070  0.263889  0.262463
90   0.282135  0.251113  0.252029
105  0.271487  0.238350  0.239573
120  0.262332  0.229551  0.230785
135  0.253706  0.221471  0.222859
150  0.243264  0.215901  0.217705
165  0.236092  0.211969  0.214789
180  0.230552  0.206191  0.209184
195  0.227198  0.201775  0.204043

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.653028  0.652045
15   0.419014  0.398354  0.397242
30   0.355150  0.324895  0.327059
45   0.327888  0.302424  0.302278
60   0.313217  0.286330  0.284091
75   0.303062  0.270972  0.269662
90   0.288764  0.258979  0.259941
105  0.278745  0.247014  0.248217
120  0.270235  0.239049  0.240260
135  0.262297  0.231796  0.233192
150  0.252516  0.227110  0.228815
165  0.246085  0.224040  0.226841
180  0.241248  0.219069  0.222077
195  0.238583  0.215493  0.217705

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.136001  0.099881
f29  0.096434  0.097866  0.087777
f16  0.095221  0.092049  0.078846
f24  0.070382  0.067726  0.128869
f9   0.066337  0.063649  0.074207


{'num_leaves': 1024, 'max_depth': 10, 'n_train': 2000000}
training XGBoost
[01:37:42] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 112.4428563117981 seconds
[01:39:35] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 112.71194291114807 seconds
training LightGBM
LightGBM: 57.79952907562256 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.648192  0.648192  0.647304
15   0.364879  0.364879  0.365586
30   0.291926  0.291926  0.294661
45   0.270327  0.270327  0.265765
60   0.251356  0.251356  0.251843
75   0.239048  0.239048  0.239441
90   0.223576  0.223576  0.222618
105  0.214349  0.214349  0.211009
120  0.205396  0.205396  0.201603
135  0.200692  0.200692  0.194081
150  0.191552  0.191552  0.189724
165  0.183042  0.183042  0.184572
180  0.180105  0.180105  0.179099
195  0.177657  0.177657  0.174406

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648686  0.648686  0.647816
15   0.370408  0.370408  0.370942
30   0.300284  0.300284  0.302599
45   0.280182  0.280182  0.275397
60   0.262590  0.262590  0.262766
75   0.251719  0.251719  0.251635
90   0.237951  0.237951  0.236612
105  0.230147  0.230147  0.226704
120  0.222882  0.222882  0.219129
135  0.219705  0.219705  0.213382
150  0.212423  0.212423  0.210788
165  0.205749  0.205749  0.207208
180  0.204338  0.204338  0.203604
195  0.203393  0.203393  0.200372

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         985       985  983
15        985       985  963
30        858       858  803
45        545       545  933
60        428       428  769
75        841       841  418
90        819       819  694
105       591       591  709
120       486       486  629
135       651       651  394
150       873       873  478
165       817       817  665
180       424       424  743
195       548       548  849

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.131471  0.131471  0.097966
f29  0.097900  0.097900  0.088943
f16  0.088010  0.088010  0.076814
f24  0.072497  0.072497  0.123784
f9   0.062764  0.062764  0.069709


{'num_leaves': 32, 'max_depth': 15, 'n_train': 2000000}
training XGBoost
[01:42:32] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 40.134522676467896 seconds
[01:43:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 38.894954442977905 seconds
training LightGBM
LightGBM: 25.80644416809082 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492764  0.491935
30   0.458417  0.432709  0.432188
45   0.428591  0.401036  0.402481
60   0.412332  0.381574  0.381095
75   0.397652  0.368847  0.369144
90   0.387497  0.355976  0.356675
105  0.378310  0.345112  0.347515
120  0.368572  0.336908  0.338233
135  0.360008  0.331494  0.331846
150  0.353769  0.325300  0.323982
165  0.349606  0.317515  0.318516
180  0.344543  0.312189  0.311204
195  0.337779  0.306237  0.307261

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493906  0.493109
30   0.459662  0.434252  0.433647
45   0.430273  0.402868  0.404301
60   0.414270  0.383712  0.383136
75   0.399854  0.371223  0.371385
90   0.389975  0.358468  0.359087
105  0.381044  0.347838  0.350122
120  0.371437  0.339798  0.341065
135  0.362940  0.334504  0.334815
150  0.356809  0.328406  0.327114
165  0.352735  0.320802  0.321812
180  0.347761  0.315648  0.314658
195  0.341143  0.309779  0.310849

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.137166  0.116649
f29  0.096980  0.100548  0.097949
f16  0.087717  0.093916  0.085372
f31  0.074015  0.085031  0.035618
f12  0.066929  0.057137  0.058591


{'num_leaves': 256, 'max_depth': 15, 'n_train': 2000000}
training XGBoost
[01:44:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 71.26948952674866 seconds
[01:45:30] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 70.4212999343872 seconds
training LightGBM
LightGBM: 46.65948939323425 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652332  0.651208
15   0.416301  0.389403  0.389860
30   0.351350  0.310204  0.309492
45   0.323185  0.279427  0.281829
60   0.307805  0.257062  0.260335
75   0.297070  0.242686  0.243533
90   0.282135  0.233639  0.232481
105  0.271487  0.226250  0.224319
120  0.262332  0.219441  0.217465
135  0.253706  0.215145  0.212750
150  0.243264  0.210053  0.209232
165  0.236092  0.204692  0.205744
180  0.230552  0.201650  0.201731
195  0.227198  0.198414  0.199107

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.652657  0.651481
15   0.419014  0.392599  0.393096
30   0.355150  0.314945  0.314360
45   0.327888  0.285217  0.287844
60   0.313217  0.263842  0.267147
75   0.303062  0.250386  0.251208
90   0.288764  0.242166  0.241061
105  0.278745  0.235564  0.233799
120  0.270235  0.229626  0.227877
135  0.262297  0.226241  0.224076
150  0.252516  0.222083  0.221437
165  0.246085  0.217644  0.218918
180  0.241248  0.215639  0.215667
195  0.238583  0.213325  0.213959

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.142190  0.099271
f29  0.096434  0.095742  0.087326
f16  0.095221  0.090654  0.078728
f24  0.070382  0.068764  0.128522
f9   0.066337  0.062362  0.072408


{'num_leaves': 1024, 'max_depth': 15, 'n_train': 2000000}
training XGBoost
[01:47:29] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 131.94913911819458 seconds
[01:49:42] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 135.59927821159363 seconds
training LightGBM
LightGBM: 65.5693747997284 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.647957  0.642051  0.641569
15   0.364843  0.329033  0.328001
30   0.291531  0.247037  0.246351
45   0.262601  0.218827  0.219192
60   0.241492  0.201040  0.201291
75   0.223358  0.188844  0.187092
90   0.208667  0.178791  0.177429
105  0.198864  0.172384  0.171602
120  0.191361  0.166199  0.166671
135  0.183881  0.162036  0.160279
150  0.175894  0.156325  0.155653
165  0.170904  0.151755  0.152148
180  0.166972  0.146606  0.148373
195  0.161532  0.142182  0.144454

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648459  0.642706  0.642215
15   0.370401  0.335989  0.335014
30   0.300153  0.257969  0.257184
45   0.273498  0.232734  0.233035
60   0.254403  0.217737  0.217809
75   0.238466  0.208457  0.206466
90   0.225990  0.201775  0.200108
105  0.218446  0.198791  0.197796
120  0.213346  0.195900  0.196189
135  0.208342  0.194933  0.192994
150  0.202814  0.192380  0.191435
165  0.200317  0.190673  0.191106
180  0.198599  0.188419  0.190142
195  0.195623  0.186741  0.189252

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.120410  0.128027  0.093003
f29  0.093475  0.088748  0.085148
f16  0.084261  0.084880  0.075484
f24  0.074033  0.073298  0.122135
f8   0.062958  0.058484  0.089409


{'num_leaves': 4096, 'max_depth': 15, 'n_train': 2000000}
training XGBoost
[01:53:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 279.20873737335205 seconds
[01:57:55] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 283.40815830230713 seconds
training LightGBM
LightGBM: 109.57961654663086 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.639568  0.633948  0.633987
15   0.313271  0.282930  0.282593
30   0.233586  0.199557  0.199535
45   0.198225  0.166658  0.168971
60   0.177924  0.150070  0.153832
75   0.156173  0.138522  0.138794
90   0.143805  0.130463  0.129635
105  0.135069  0.122695  0.122155
120  0.126857  0.115850  0.114646
135  0.119711  0.109853  0.108534
150  0.114728  0.103052  0.105042
165  0.109073  0.096128  0.096610
180  0.101888  0.090397  0.091888
195  0.095594  0.084521  0.085023

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.640793  0.635462  0.635566
15   0.326588  0.299185  0.299031
30   0.254553  0.225802  0.226068
45   0.226202  0.201993  0.204156
60   0.211672  0.191832  0.195018
75   0.196742  0.186291  0.186851
90   0.190958  0.184805  0.184355
105  0.188376  0.182554  0.181368
120  0.185476  0.181184  0.180166
135  0.183229  0.179229  0.179015
150  0.182545  0.177351  0.178475
165  0.181263  0.175964  0.176131
180  0.178798  0.174955  0.175711
195  0.177058  0.173734  0.174507

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      4096  2992
75       4096      1622  1513
90       4096      4096  4096
105      4096      3796  2613
120      4023      1021  2377
135      4096      2116  3392
150      1010      3906  2235
165       579      2417  3971
180      4096      4096  4096
195      3970      3196  3201

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.109821  0.112321  0.089391
f29  0.086451  0.084541  0.080327
f16  0.080207  0.078688  0.072006
f24  0.075662  0.074335  0.116479
f8   0.062408  0.061281  0.085817


{'num_leaves': 32, 'max_depth': 20, 'n_train': 2000000}
training XGBoost
[02:04:54] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 40.443023443222046 seconds
[02:05:35] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 37.615522384643555 seconds
training LightGBM
LightGBM: 25.6999351978302 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492764  0.491935
30   0.458417  0.433222  0.432188
45   0.428591  0.401738  0.402477
60   0.412332  0.381896  0.379921
75   0.397652  0.367902  0.366945
90   0.387497  0.356728  0.353551
105  0.378310  0.348882  0.344919
120  0.368572  0.340144  0.338169
135  0.360008  0.332757  0.330754
150  0.353769  0.325746  0.325658
165  0.349606  0.319835  0.320465
180  0.344543  0.315430  0.314185
195  0.337779  0.309952  0.307976

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493906  0.493109
30   0.459662  0.434793  0.433647
45   0.430273  0.403679  0.404300
60   0.414270  0.384145  0.382006
75   0.399854  0.370442  0.369270
90   0.389975  0.359480  0.356086
105  0.381044  0.351759  0.347650
120  0.371437  0.343178  0.341063
135  0.362940  0.335944  0.333800
150  0.356809  0.329055  0.328793
165  0.352735  0.323326  0.323691
180  0.347761  0.319031  0.317519
195  0.341143  0.313676  0.311469

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.139808  0.115819
f29  0.096980  0.094510  0.097201
f16  0.087717  0.088024  0.084202
f31  0.074015  0.082002  0.033879
f12  0.066929  0.066952  0.059828


{'num_leaves': 256, 'max_depth': 20, 'n_train': 2000000}
training XGBoost
[02:06:39] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 71.58948183059692 seconds
[02:07:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 72.00103569030762 seconds
training LightGBM
LightGBM: 47.72133469581604 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652332  0.651194
15   0.416301  0.390072  0.389215
30   0.351350  0.307483  0.307969
45   0.323185  0.271729  0.273141
60   0.307805  0.250788  0.253333
75   0.297070  0.239523  0.241645
90   0.282135  0.230279  0.231909
105  0.271487  0.221768  0.222220
120  0.262332  0.216983  0.215063
135  0.253706  0.210671  0.210620
150  0.243264  0.206110  0.206169
165  0.236092  0.201668  0.202626
180  0.230552  0.199470  0.199018
195  0.227198  0.197128  0.194679

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.652657  0.651466
15   0.419014  0.393276  0.392438
30   0.355150  0.312305  0.312857
45   0.327888  0.277716  0.279107
60   0.313217  0.257691  0.260192
75   0.303062  0.247327  0.249381
90   0.288764  0.238973  0.240475
105  0.278745  0.231277  0.231628
120  0.270235  0.227369  0.225336
135  0.262297  0.221940  0.221863
150  0.252516  0.218310  0.218331
165  0.246085  0.214776  0.215757
180  0.241248  0.213599  0.213127
195  0.238583  0.212206  0.209731

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.139886  0.097955
f29  0.096434  0.092662  0.085761
f16  0.095221  0.088697  0.081260
f24  0.070382  0.070674  0.126405
f9   0.066337  0.062238  0.074380


{'num_leaves': 1024, 'max_depth': 20, 'n_train': 2000000}
training XGBoost
[02:09:54] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 133.5889115333557 seconds
[02:12:08] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 128.04701733589172 seconds
training LightGBM
LightGBM: 65.11594748497009 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.647957  0.641910  0.641413
15   0.364843  0.327983  0.328675
30   0.291531  0.242923  0.244298
45   0.262601  0.209299  0.209565
60   0.241492  0.189310  0.190855
75   0.223358  0.178215  0.177900
90   0.208667  0.172201  0.172284
105  0.198864  0.166643  0.167586
120  0.191361  0.160857  0.161393
135  0.183881  0.155487  0.156361
150  0.175894  0.151459  0.150934
165  0.170904  0.147283  0.147022
180  0.166730  0.143837  0.142238
195  0.159862  0.140429  0.138765

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648459  0.642562  0.642060
15   0.370401  0.335102  0.335665
30   0.300153  0.253984  0.255394
45   0.273498  0.223411  0.223878
60   0.254403  0.206357  0.208107
75   0.238466  0.198666  0.198499
90   0.225990  0.196271  0.196741
105  0.218446  0.194467  0.195825
120  0.213346  0.192255  0.193126
135  0.208342  0.190365  0.191197
150  0.202814  0.189819  0.189039
165  0.200317  0.188932  0.188287
180  0.198392  0.188424  0.186693
195  0.193844  0.188016  0.185985

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.121470  0.126762  0.093182
f29  0.093262  0.091559  0.084571
f16  0.084588  0.084249  0.075069
f24  0.073451  0.072932  0.121235
f8   0.062614  0.060079  0.090615


{'num_leaves': 4096, 'max_depth': 20, 'n_train': 2000000}
training XGBoost
[02:15:30] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_dw: 318.7143635749817 seconds
[02:20:53] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using default sequence of updaters: grow_fast_histmaker,prune
EQBIN_lg: 344.2623007297516 seconds
training LightGBM
LightGBM: 129.1721830368042 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.639568  0.632341  0.632336
15   0.313271  0.273735  0.273573
30   0.233586  0.186708  0.185923
45   0.198093  0.152459  0.150712
60   0.173090  0.133472  0.132075
75   0.153095  0.118241  0.118056
90   0.139472  0.107197  0.107507
105  0.130807  0.098607  0.098537
120  0.120023  0.091047  0.090732
135  0.109868  0.084440  0.083136
150  0.102103  0.075567  0.075833
165  0.095141  0.068567  0.068982
180  0.088646  0.062483  0.062604
195  0.082366  0.056444  0.057873

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.640793  0.633997  0.633994
15   0.326588  0.291041  0.290932
30   0.254553  0.214966  0.214197
45   0.226137  0.191327  0.189770
60   0.207948  0.182071  0.181137
75   0.195296  0.177586  0.177271
90   0.188616  0.175777  0.176015
105  0.186630  0.174563  0.174590
120  0.182771  0.173474  0.173725
135  0.179429  0.172978  0.173084
150  0.177807  0.171085  0.171798
165  0.176607  0.169982  0.170425
180  0.175692  0.169322  0.169789
195  0.175199  0.168851  0.169530

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      4096  4096
75       4096      4096  4096
90       4096      3821  4096
105      4096      1000  4096
120      4096      1824  4096
135      4096      2148  4096
150      4096      4096  4096
165      3490      4096  3084
180      4096      4096  4096
195      4096      4096  4096

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.106217  0.109633  0.087486
f29  0.084707  0.083104  0.078489
f16  0.078629  0.076426  0.071003
f24  0.077138  0.073446  0.112226
f8   0.062991  0.059580  0.086101


                             Time(sec)                        Ratio             
                              EQBIN_dw EQBIN_lg    LGB EQBIN_dw/LGB EQBIN_lg/LGB
n_train max_depth num_leaves                                                    
500000  5         32              12.4     11.9    5.2          2.4          2.3
        10        32              12.2     11.8    6.0          2.0          2.0
                  256             30.8     31.7   11.5          2.7          2.8
                  1024            47.1     46.9   14.3          3.3          3.3
        15        32              12.0     11.9    6.3          1.9          1.9
                  256             31.1     30.7   11.5          2.7          2.7
                  1024            79.0     80.8   22.0          3.6          3.7
                  4096           143.1    143.9   35.3          4.1          4.1
        20        32              12.1     11.6    6.1          2.0          1.9
                  256             31.5     30.4   11.8          2.7          2.6
                  1024            80.3     83.8   24.2          3.3          3.5
                  4096           205.7    210.3   52.8          3.9          4.0
1000000 5         32              22.6     22.2   10.8          2.1          2.0
        10        32              22.0     21.2   13.0          1.7          1.6
                  256             44.9     45.6   22.7          2.0          2.0
                  1024            72.2     71.0   27.2          2.6          2.6
        15        32              21.8     21.7   13.0          1.7          1.7
                  256             44.0     44.7   22.7          1.9          2.0
                  1024            99.4    102.5   37.5          2.6          2.7
                  4096           210.0    207.1   62.3          3.4          3.3
        20        32              21.7     21.8   13.1          1.7          1.7
                  256             45.0     47.9   23.3          1.9          2.1
                  1024           100.8    101.0   37.3          2.7          2.7
                  4096           261.9    285.9   88.7          3.0          3.2
2000000 5         32              41.1     40.0   22.5          1.8          1.8
        10        32              39.9     38.9   25.8          1.5          1.5
                  256             74.2     76.6   46.7          1.6          1.6
                  1024           112.4    112.7   57.8          1.9          2.0
        15        32              40.1     38.9   25.8          1.6          1.5
                  256             71.3     70.4   46.7          1.5          1.5
                  1024           131.9    135.6   65.6          2.0          2.1
                  4096           279.2    283.4  109.6          2.5          2.6
        20        32              40.4     37.6   25.7          1.6          1.5
                  256             71.6     72.0   47.7          1.5          1.5
                  1024           133.6    128.0   65.1          2.1          2.0
                  4096           318.7    344.3  129.2          2.5          2.7

Logloss
                              EQBIN_dw  EQBIN_lg     LGB  EQBIN_lg-LGB
n_train max_depth num_leaves                                          
500000  5         32            0.3630    0.3630  0.3623        0.0007
        10        32            0.3608    0.3299  0.3331       -0.0032
                  256           0.2673    0.2536  0.2551       -0.0015
                  1024          0.2484    0.2484  0.2431        0.0054
        15        32            0.3608    0.3280  0.3254        0.0026
                  256           0.2680    0.2546  0.2556       -0.0010
                  1024          0.2322    0.2272  0.2268        0.0004
                  4096          0.2226    0.2202  0.2216       -0.0014
        20        32            0.3608    0.3308  0.3330       -0.0022
                  256           0.2680    0.2518  0.2505        0.0013
                  1024          0.2313    0.2240  0.2230        0.0010
                  4096          0.2204    0.2188  0.2198       -0.0009
1000000 5         32            0.3427    0.3427  0.3431       -0.0004
        10        32            0.3429    0.3164  0.3149        0.0015
                  256           0.2497    0.2394  0.2396       -0.0001
                  1024          0.2276    0.2276  0.2291       -0.0015
        15        32            0.3429    0.3123  0.3139       -0.0017
                  256           0.2517    0.2330  0.2354       -0.0024
                  1024          0.2183    0.2101  0.2086        0.0015
                  4096          0.2032    0.2012  0.2009        0.0003
        20        32            0.3429    0.3117  0.3128       -0.0011
                  256           0.2517    0.2312  0.2321       -0.0009
                  1024          0.2161    0.2080  0.2086       -0.0006
                  4096          0.2002    0.1982  0.1980        0.0002
2000000 5         32            0.3398    0.3398  0.3342        0.0056
        10        32            0.3389    0.3138  0.3091        0.0047
                  256           0.2374    0.2147  0.2172       -0.0025
                  1024          0.2027    0.2027  0.1996        0.0031
        15        32            0.3389    0.3084  0.3098       -0.0015
                  256           0.2374    0.2131  0.2135       -0.0004
                  1024          0.1950    0.1865  0.1890       -0.0025
                  4096          0.1767    0.1738  0.1742       -0.0004
        20        32            0.3389    0.3119  0.3105        0.0014
                  256           0.2374    0.2120  0.2088        0.0033
                  1024          0.1932    0.1881  0.1855        0.0026
                  4096          0.1750    0.1687  0.1693       -0.0006

Done: 7634.793365716934 seconds
