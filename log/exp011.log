

{'num_leaves': 32, 'n_train': 500000, 'max_depth': 5}
training XGBoost
[03:50:35] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 12.186813116073608 seconds
[03:50:47] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 11.89838171005249 seconds
training LightGBM
LightGBM: 5.192061185836792 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.675223  0.675159
15   0.538657  0.538657  0.536850
30   0.489796  0.489796  0.487917
45   0.461254  0.461254  0.460996
60   0.443328  0.443328  0.443085
75   0.422786  0.422786  0.427510
90   0.407351  0.407351  0.416744
105  0.392894  0.392894  0.404913
120  0.385819  0.385819  0.393944
135  0.379876  0.379876  0.385745
150  0.373250  0.373250  0.378372
165  0.366858  0.366858  0.370963
180  0.361597  0.361597  0.363289
195  0.357106  0.357106  0.357302

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.675327  0.675282
15   0.540042  0.540042  0.538393
30   0.491851  0.491851  0.490047
45   0.463598  0.463598  0.463464
60   0.446067  0.446067  0.446023
75   0.426136  0.426136  0.430857
90   0.411187  0.411187  0.420516
105  0.397151  0.397151  0.409005
120  0.390497  0.390497  0.398496
135  0.384954  0.384954  0.390699
150  0.378667  0.378667  0.383539
165  0.372594  0.372594  0.376521
180  0.367742  0.367742  0.369207
195  0.363628  0.363628  0.363677

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         30        30   29
75         30        30   32
90         30        30   32
105        32        32   31
120        31        31   32
135        32        32   31
150        32        32   32
165        32        32   32
180        31        31   32
195        30        30   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125244  0.125244  0.139206
f1   0.077363  0.077363  0.043795
f7   0.073242  0.073242  0.098834
f17  0.070430  0.070430  0.055687
f5   0.068089  0.068089  0.054752


{'num_leaves': 32, 'n_train': 500000, 'max_depth': 10}
training XGBoost
[03:51:05] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 12.54668402671814 seconds
[03:51:17] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 11.874740839004517 seconds
training LightGBM
LightGBM: 5.986418724060059 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.507373  0.504056
30   0.489796  0.452641  0.450193
45   0.461254  0.424939  0.421044
60   0.441973  0.405291  0.400745
75   0.424671  0.389522  0.387223
90   0.409568  0.373764  0.376561
105  0.402111  0.363740  0.365810
120  0.391036  0.355245  0.356653
135  0.383902  0.347198  0.348178
150  0.375794  0.340875  0.340077
165  0.367041  0.334307  0.336314
180  0.362225  0.329864  0.331132
195  0.356370  0.322570  0.325978

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.508494  0.505676
30   0.491851  0.454354  0.452610
45   0.463598  0.427174  0.423845
60   0.444825  0.408179  0.404021
75   0.428041  0.393146  0.391019
90   0.413417  0.377977  0.380836
105  0.406221  0.368565  0.370526
120  0.395504  0.360624  0.361898
135  0.388673  0.353099  0.353956
150  0.381016  0.347152  0.346390
165  0.372565  0.341059  0.343069
180  0.368032  0.337215  0.338456
195  0.362488  0.330534  0.333815

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.127673  0.136560
f7   0.077845  0.064583  0.094765
f1   0.072288  0.069269  0.037269
f9   0.067771  0.071354  0.085388
f17  0.067761  0.063767  0.052060


{'num_leaves': 256, 'n_train': 500000, 'max_depth': 10}
training XGBoost
[03:51:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 31.1111843585968 seconds
[03:52:07] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 31.358383417129517 seconds
training LightGBM
LightGBM: 10.927976131439209 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.654859  0.655016
15   0.445656  0.412285  0.411963
30   0.386099  0.343984  0.345963
45   0.345863  0.314970  0.314964
60   0.324551  0.295087  0.297044
75   0.306972  0.278582  0.279776
90   0.294403  0.267757  0.265181
105  0.280862  0.259438  0.256810
120  0.270997  0.250853  0.247393
135  0.264641  0.242579  0.238975
150  0.255665  0.234124  0.231507
165  0.248372  0.225951  0.224825
180  0.239119  0.218516  0.218838
195  0.234054  0.214080  0.213493

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.655368  0.655577
15   0.449799  0.417807  0.417653
30   0.393282  0.353205  0.355185
45   0.355624  0.327243  0.326952
60   0.336659  0.310049  0.311699
75   0.321291  0.296213  0.297242
90   0.310871  0.287915  0.285630
105  0.299856  0.282387  0.279879
120  0.292293  0.276905  0.273601
135  0.288390  0.271804  0.268586
150  0.281990  0.266263  0.264450
165  0.277379  0.261208  0.261002
180  0.270612  0.256418  0.258079
195  0.268253  0.255184  0.255278

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  205
75        256       256  256
90        256       218  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       217  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.118651  0.113403  0.117106
f9   0.073339  0.066822  0.069162
f7   0.068624  0.064389  0.085848
f17  0.059297  0.055403  0.048813
f31  0.059139  0.067048  0.069502


{'num_leaves': 1024, 'n_train': 500000, 'max_depth': 10}
training XGBoost
[03:52:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 47.684406757354736 seconds
[03:53:39] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 46.45238661766052 seconds
training LightGBM
LightGBM: 14.035467624664307 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.651639  0.651639  0.651787
15   0.390788  0.390788  0.392943
30   0.324340  0.324340  0.321290
45   0.296892  0.296892  0.292872
60   0.274448  0.274448  0.275292
75   0.257760  0.257760  0.253256
90   0.244864  0.244864  0.239813
105  0.234966  0.234966  0.231397
120  0.223411  0.223411  0.219463
135  0.214793  0.214793  0.212184
150  0.208904  0.208904  0.204523
165  0.200966  0.200966  0.193077
180  0.194875  0.194875  0.184832
195  0.189971  0.189971  0.179449

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.652533  0.652533  0.652749
15   0.401175  0.401175  0.403284
30   0.340391  0.340391  0.337177
45   0.316944  0.316944  0.312927
60   0.298326  0.298326  0.298676
75   0.285349  0.285349  0.281720
90   0.276250  0.276250  0.271969
105  0.270693  0.270693  0.267390
120  0.263494  0.263494  0.260120
135  0.259340  0.259340  0.257021
150  0.257408  0.257408  0.253541
165  0.253312  0.253312  0.247345
180  0.250792  0.250792  0.244359
195  0.248831  0.248831  0.243347

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         852       852  844
15        745       745  787
30        521       521  507
45        413       413  550
60        723       723  324
75        172       172  796
90        342       342  500
105       302       302  150
120       759       759  333
135       373       373  501
150       399       399  816
165       400       400  548
180       578       578  418
195       249       249  450

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.115447  0.115447  0.112753
f9   0.068445  0.068445  0.067044
f7   0.063394  0.063394  0.082829
f31  0.063055  0.063055  0.069558
f10  0.057661  0.057661  0.092848


{'num_leaves': 32, 'n_train': 500000, 'max_depth': 15}
training XGBoost
[03:54:44] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 12.05843448638916 seconds
[03:54:56] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 12.050704717636108 seconds
training LightGBM
LightGBM: 6.124403476715088 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.504339  0.505071
30   0.489796  0.448982  0.449470
45   0.461254  0.419500  0.418257
60   0.441973  0.399314  0.397380
75   0.424671  0.384352  0.380460
90   0.409568  0.371749  0.368609
105  0.402111  0.360344  0.359724
120  0.391036  0.349898  0.351468
135  0.383902  0.342412  0.342732
150  0.375794  0.336676  0.335642
165  0.367041  0.332410  0.329198
180  0.362225  0.326543  0.323556
195  0.356370  0.321183  0.318037

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.505683  0.506502
30   0.491851  0.450852  0.451511
45   0.463598  0.421869  0.420962
60   0.444825  0.402349  0.400770
75   0.428041  0.388088  0.384485
90   0.413417  0.376058  0.373277
105  0.406221  0.365294  0.364934
120  0.395504  0.355332  0.357278
135  0.388673  0.348370  0.349151
150  0.381016  0.343221  0.342505
165  0.372565  0.339496  0.336528
180  0.368032  0.334133  0.331519
195  0.362488  0.329340  0.326478

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.126979  0.136217
f7   0.077845  0.066851  0.091529
f1   0.072288  0.081684  0.038298
f9   0.067771  0.071102  0.083204
f17  0.067761  0.065601  0.050563


{'num_leaves': 256, 'n_train': 500000, 'max_depth': 15}
training XGBoost
[03:55:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 31.819329023361206 seconds
[03:55:47] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 30.684418439865112 seconds
training LightGBM
LightGBM: 11.123687982559204 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.653653  0.653966
15   0.445656  0.396437  0.397702
30   0.386099  0.319544  0.323089
45   0.345863  0.290004  0.292334
60   0.324551  0.271027  0.274777
75   0.307560  0.257728  0.259717
90   0.293811  0.246880  0.250524
105  0.281713  0.240516  0.244159
120  0.270883  0.234158  0.238195
135  0.260389  0.229712  0.232565
150  0.251743  0.222241  0.228049
165  0.244601  0.215327  0.218883
180  0.239018  0.210774  0.213127
195  0.234650  0.206706  0.208882

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.654242  0.654562
15   0.449799  0.402374  0.404126
30   0.393282  0.329378  0.332842
45   0.355624  0.303014  0.305400
60   0.336659  0.287085  0.290906
75   0.321924  0.277238  0.279335
90   0.310479  0.269961  0.273815
105  0.300796  0.267413  0.270970
120  0.292384  0.264856  0.268420
135  0.284450  0.264075  0.266285
150  0.278564  0.259935  0.265198
165  0.274273  0.256133  0.259088
180  0.271338  0.255453  0.256705
195  0.269654  0.254698  0.255760

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.119129  0.113184  0.114545
f9   0.072751  0.068910  0.069879
f7   0.069169  0.062379  0.084403
f10  0.059257  0.058302  0.094745
f17  0.058706  0.051032  0.048781


{'num_leaves': 1024, 'n_train': 500000, 'max_depth': 15}
training XGBoost
[03:56:31] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 79.1106367111206 seconds
[03:57:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 81.52642393112183 seconds
training LightGBM
LightGBM: 21.671100854873657 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650728  0.643126  0.643179
15   0.381140  0.336316  0.336360
30   0.305366  0.252789  0.253922
45   0.266276  0.218436  0.219400
60   0.239462  0.201520  0.201049
75   0.220427  0.184453  0.186899
90   0.202603  0.173328  0.173162
105  0.191875  0.161192  0.162216
120  0.180153  0.149300  0.150966
135  0.167028  0.139448  0.140027
150  0.157270  0.131558  0.130374
165  0.149207  0.122681  0.121893
180  0.141134  0.114982  0.113722
195  0.132256  0.107239  0.106911

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651801  0.644820  0.644782
15   0.393680  0.353735  0.353742
30   0.326315  0.282074  0.283002
45   0.294495  0.258017  0.258783
60   0.274747  0.249367  0.248672
75   0.262881  0.242585  0.244101
90   0.253732  0.240142  0.240588
105  0.250122  0.236741  0.238337
120  0.246481  0.233530  0.235141
135  0.241153  0.231894  0.232236
150  0.238898  0.230694  0.230141
165  0.237557  0.229376  0.229201
180  0.235415  0.228396  0.227815
195  0.232610  0.227252  0.226842

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024       817  1024
75       1024      1024  1024
90       1024      1024   659
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165       629      1024  1024
180      1024      1024   573
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.104525  0.099508  0.104424
f9   0.065486  0.063380  0.061893
f7   0.063335  0.059417  0.073818
f31  0.063033  0.064322  0.069396
f10  0.058011  0.057214  0.088218


{'num_leaves': 4096, 'n_train': 500000, 'max_depth': 15}
training XGBoost
[03:59:41] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 145.14956951141357 seconds
[04:02:09] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 143.1944272518158 seconds
training LightGBM
LightGBM: 34.813371419906616 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.638249  0.635119  0.635122
15   0.304004  0.287983  0.287461
30   0.210452  0.192443  0.193864
45   0.178598  0.161888  0.161640
60   0.161279  0.149479  0.149547
75   0.144680  0.133556  0.135945
90   0.131739  0.119178  0.123650
105  0.118691  0.106468  0.113591
120  0.104918  0.096595  0.100849
135  0.095043  0.087608  0.089675
150  0.086893  0.079124  0.083026
165  0.078863  0.072085  0.074580
180  0.071321  0.067092  0.068500
195  0.065756  0.059248  0.063122

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.641995  0.639688  0.639394
15   0.342940  0.332860  0.332462
30   0.272719  0.263850  0.264326
45   0.252559  0.245412  0.244684
60   0.243413  0.239214  0.238880
75   0.237795  0.232962  0.235305
90   0.234783  0.229043  0.232013
105  0.232045  0.226292  0.229820
120  0.229127  0.225153  0.227006
135  0.227567  0.224299  0.224769
150  0.225802  0.222758  0.224008
165  0.224652  0.221945  0.222659
180  0.224101  0.221395  0.221912
195  0.223289  0.220479  0.221522

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       3185      3649  3452
45       1699      2252  2891
60       1362       978  1391
75        430       584  3274
90       4096       516  1044
105      1926      1621  1317
120      3266       565  2591
135      4096      2373  1900
150      4096       558  3006
165       801      2429   774
180      3162       909  1612
195       762      3391   508

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.097489  0.096947  0.101085
f9   0.062846  0.061169  0.060428
f31  0.061997  0.062953  0.070731
f7   0.057490  0.057339  0.070512
f10  0.055121  0.054940  0.082614


{'num_leaves': 16384, 'n_train': 500000, 'max_depth': 15}
training XGBoost
[04:05:24] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 156.7322974205017 seconds
[04:08:03] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 155.4611098766327 seconds
training LightGBM
LightGBM: 49.82726001739502 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.633882  0.633882  0.634062
15   0.281393  0.281393  0.282779
30   0.188958  0.188958  0.187786
45   0.161164  0.161164  0.159353
60   0.146568  0.146568  0.148801
75   0.134437  0.134437  0.134259
90   0.117677  0.117677  0.122401
105  0.106300  0.106300  0.113138
120  0.096707  0.096707  0.105040
135  0.087125  0.087125  0.096758
150  0.076294  0.076294  0.087070
165  0.069482  0.069482  0.078659
180  0.063461  0.063461  0.070966
195  0.056269  0.056269  0.063410

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.639428  0.639428  0.639157
15   0.331964  0.331964  0.332082
30   0.264912  0.264912  0.263490
45   0.247136  0.247136  0.245828
60   0.239228  0.239228  0.240373
75   0.235107  0.235107  0.235247
90   0.231170  0.231170  0.231759
105  0.229382  0.229382  0.229973
120  0.228073  0.228073  0.228375
135  0.226080  0.226080  0.227578
150  0.224066  0.224066  0.226301
165  0.223107  0.223107  0.224678
180  0.222768  0.222768  0.223782
195  0.221728  0.221728  0.222747

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        6423      6423  6354
15       5409      5409  6243
30       3025      3025  3665
45       1478      1478  1315
60       1396      1396  1684
75       1126      1126  1654
90       2916      2916  2396
105      1637      1637  1733
120      1070      1070  1843
135      1788      1788  1314
150      3349      3349  2360
165      2555      2555  1220
180      1466      1466  1987
195      1473      1473  1254

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.096565  0.096565  0.101543
f9   0.063090  0.063090  0.059776
f31  0.062483  0.062483  0.070079
f7   0.056901  0.056901  0.069734
f10  0.055802  0.055802  0.082661


{'num_leaves': 32, 'n_train': 500000, 'max_depth': 20}
training XGBoost
[04:11:47] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 12.487859010696411 seconds
[04:11:59] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 11.981048822402954 seconds
training LightGBM
LightGBM: 6.0200700759887695 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.675223  0.669968  0.669964
15   0.538657  0.504339  0.505071
30   0.489796  0.448949  0.447672
45   0.461254  0.420841  0.419927
60   0.441973  0.402737  0.400765
75   0.424671  0.389002  0.383045
90   0.409568  0.375777  0.371528
105  0.402111  0.365269  0.361442
120  0.391036  0.357292  0.355231
135  0.383902  0.349877  0.348110
150  0.375794  0.342334  0.342293
165  0.367041  0.334894  0.335972
180  0.362225  0.328755  0.330748
195  0.356370  0.323611  0.325765

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.675327  0.670061  0.670104
15   0.540042  0.505683  0.506502
30   0.491851  0.450813  0.449614
45   0.463598  0.423050  0.422468
60   0.444825  0.405542  0.403883
75   0.428041  0.392532  0.386883
90   0.413417  0.379991  0.375897
105  0.406221  0.370130  0.366401
120  0.395504  0.362799  0.360631
135  0.388673  0.355917  0.353985
150  0.381016  0.348882  0.348559
165  0.372565  0.342056  0.342742
180  0.368032  0.336465  0.338064
195  0.362488  0.331837  0.333689

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.125269  0.125244  0.137626
f7   0.077845  0.064981  0.089094
f1   0.072288  0.077573  0.038883
f9   0.067771  0.069495  0.087749
f17  0.067761  0.068597  0.049599


{'num_leaves': 256, 'n_train': 500000, 'max_depth': 20}
training XGBoost
[04:12:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 31.572309970855713 seconds
[04:12:49] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 30.901235342025757 seconds
training LightGBM
LightGBM: 11.646154642105103 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.660419  0.653653  0.653966
15   0.445656  0.395474  0.396297
30   0.386099  0.317459  0.318905
45   0.345863  0.283433  0.284111
60   0.324551  0.263905  0.263636
75   0.307560  0.253387  0.253100
90   0.293811  0.245690  0.246459
105  0.281713  0.239653  0.238939
120  0.270883  0.233274  0.232942
135  0.260389  0.227804  0.227143
150  0.251743  0.222555  0.220927
165  0.244601  0.216768  0.214362
180  0.239018  0.211587  0.209370
195  0.234650  0.205142  0.203138

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.660835  0.654242  0.654562
15   0.449799  0.401607  0.402703
30   0.393282  0.327482  0.328881
45   0.355624  0.296832  0.297446
60   0.336659  0.280721  0.280329
75   0.321924  0.273877  0.273566
90   0.310479  0.270201  0.270761
105  0.300796  0.267648  0.266858
120  0.292384  0.264845  0.264179
135  0.284450  0.262830  0.261840
150  0.278564  0.260868  0.258811
165  0.274273  0.257775  0.255570
180  0.271338  0.255507  0.253980
195  0.269654  0.252207  0.250770

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.119129  0.113740  0.113617
f9   0.072751  0.070219  0.069512
f7   0.069169  0.061658  0.083999
f10  0.059257  0.057785  0.095079
f17  0.058706  0.052120  0.048212


{'num_leaves': 1024, 'n_train': 500000, 'max_depth': 20}
training XGBoost
[04:13:34] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 78.85586166381836 seconds
[04:14:54] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 83.9415352344513 seconds
training LightGBM
LightGBM: 22.38715410232544 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650728  0.642855  0.642935
15   0.381140  0.332252  0.331822
30   0.305366  0.246955  0.246637
45   0.266276  0.211213  0.208533
60   0.239386  0.189230  0.186298
75   0.219788  0.174473  0.171477
90   0.205906  0.161722  0.158182
105  0.192419  0.150549  0.145442
120  0.178247  0.139181  0.135364
135  0.166934  0.129020  0.125568
150  0.156319  0.119037  0.116261
165  0.147519  0.110326  0.108521
180  0.138963  0.102022  0.100627
195  0.131748  0.094655  0.093798

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651801  0.644539  0.644562
15   0.393680  0.350114  0.349590
30   0.326315  0.277369  0.276677
45   0.294495  0.252317  0.249895
60   0.274656  0.242146  0.238810
75   0.262760  0.238951  0.235687
90   0.257027  0.236805  0.233644
105  0.251768  0.234775  0.230464
120  0.244885  0.231833  0.229434
135  0.240849  0.230303  0.227628
150  0.236798  0.228482  0.226249
165  0.234899  0.227174  0.225573
180  0.232987  0.225811  0.224262
195  0.231599  0.224417  0.223351

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.107149  0.100070  0.102359
f9   0.065546  0.064279  0.061285
f7   0.063039  0.058672  0.075125
f31  0.061679  0.062504  0.067027
f10  0.058114  0.055391  0.088461


{'num_leaves': 4096, 'n_train': 500000, 'max_depth': 20}
training XGBoost
[04:16:48] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 209.4641695022583 seconds
[04:20:21] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 213.95904922485352 seconds
training LightGBM
LightGBM: 53.20298099517822 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.638249  0.632386  0.632352
15   0.304004  0.263888  0.264590
30   0.208051  0.162379  0.162841
45   0.159551  0.120920  0.118853
60   0.139336  0.104461  0.102170
75   0.118094  0.089495  0.089318
90   0.098598  0.073592  0.076502
105  0.082876  0.060150  0.063258
120  0.068826  0.048534  0.051748
135  0.057697  0.038929  0.042693
150  0.046681  0.033873  0.033836
165  0.038105  0.026152  0.027824
180  0.032757  0.021129  0.022393
195  0.028061  0.017894  0.018855

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.641995  0.637384  0.637230
15   0.342940  0.317612  0.317858
30   0.271828  0.249819  0.250408
45   0.244324  0.230677  0.230381
60   0.235702  0.225052  0.225158
75   0.230296  0.222071  0.223451
90   0.226332  0.219748  0.220785
105  0.224279  0.217470  0.219285
120  0.222867  0.216145  0.217747
135  0.221517  0.215538  0.217128
150  0.220004  0.215756  0.216838
165  0.219737  0.216183  0.217366
180  0.219869  0.217151  0.218208
195  0.220236  0.218472  0.219485

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      2562  4096
60       3032      4096   995
75       4096      2808  1417
90       4096      4096  2443
105      2116      4096  3981
120      4096      3098  4096
135      3236      3948  2798
150      3550      2263  4096
165      2794      4096  2310
180      3912      4096  4096
195      1363      3579  1541

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.094020  0.094717  0.096635
f31  0.062246  0.064052  0.067339
f9   0.062123  0.061928  0.057588
f7   0.057860  0.056893  0.069280
f10  0.055850  0.055396  0.081935


{'num_leaves': 16384, 'n_train': 500000, 'max_depth': 20}
training XGBoost
[04:25:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 267.9160797595978 seconds
[04:29:48] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 263.60870933532715 seconds
training LightGBM
LightGBM: 88.04876255989075 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.623334  0.623334  0.623948
15   0.211492  0.211492  0.214871
30   0.107891  0.107891  0.112862
45   0.073119  0.073119  0.076540
60   0.062054  0.062054  0.063302
75   0.052974  0.052974  0.056344
90   0.045888  0.045888  0.046781
105  0.039617  0.039617  0.036965
120  0.030806  0.030806  0.032333
135  0.024551  0.024551  0.027161
150  0.020344  0.020344  0.021475
165  0.017579  0.017579  0.018303
180  0.015581  0.015581  0.016063
195  0.013935  0.013935  0.013976

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.635463  0.635463  0.634945
15   0.312379  0.312379  0.312053
30   0.246772  0.246772  0.247315
45   0.229131  0.229131  0.228971
60   0.224558  0.224558  0.223610
75   0.221997  0.221997  0.221818
90   0.220967  0.220967  0.220051
105  0.220308  0.220308  0.219428
120  0.219843  0.219843  0.219265
135  0.220263  0.220263  0.219137
150  0.220967  0.220967  0.219856
165  0.221863  0.221863  0.220959
180  0.222788  0.222788  0.221933
195  0.223667  0.223667  0.222933

Leaf counts
     EQBIN_dw  EQBIN_lg    LGB
0       15893     15893  15419
15      12647     12647  12447
30       9636      9636   8985
45       4319      4319   5741
60       1323      1323   1982
75       1905      1905   3956
90       4906      4906   3898
105      5394      5394   2916
120      4263      4263   1583
135      4633      4633   5315
150      4260      4260   4232
165      3711      3711   4049
180      1044      1044   1009
195      1046      1046   2294

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f21  0.096439  0.096439  0.098686
f31  0.064588  0.064588  0.068925
f9   0.060195  0.060195  0.057433
f7   0.055649  0.055649  0.068000
f30  0.053693  0.053693  0.047089


{'num_leaves': 32, 'n_train': 1000000, 'max_depth': 5}
training XGBoost
[04:36:22] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 22.628981113433838 seconds
[04:36:44] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 22.100844383239746 seconds
training LightGBM
LightGBM: 10.756460428237915 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.670712  0.670690
15   0.519764  0.519764  0.517547
30   0.465616  0.465616  0.462235
45   0.437321  0.437321  0.435981
60   0.416064  0.416064  0.415267
75   0.401604  0.401604  0.399342
90   0.387141  0.387141  0.386791
105  0.377943  0.377943  0.377562
120  0.371751  0.371751  0.371134
135  0.363106  0.363106  0.362164
150  0.356368  0.356368  0.355716
165  0.351519  0.351519  0.350397
180  0.344373  0.344373  0.344984
195  0.338864  0.338864  0.340146

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.670815  0.670768
15   0.520467  0.520467  0.518067
30   0.466785  0.466785  0.463390
45   0.439002  0.439002  0.437522
60   0.418094  0.418094  0.417141
75   0.403941  0.403941  0.401528
90   0.389714  0.389714  0.389355
105  0.380822  0.380822  0.380342
120  0.374910  0.374910  0.374079
135  0.366469  0.366469  0.365226
150  0.360049  0.360049  0.359005
165  0.355397  0.355397  0.353831
180  0.348419  0.348419  0.348625
195  0.343219  0.343219  0.343988

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         29        29   32
105        32        32   32
120        32        32   32
135        31        31   32
150        32        32   32
165        29        29   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.141327  0.141327  0.134151
f15  0.127395  0.127395  0.119172
f26  0.086050  0.086050  0.082649
f27  0.082321  0.082321  0.075474
f12  0.070329  0.070329  0.061019


{'num_leaves': 32, 'n_train': 1000000, 'max_depth': 10}
training XGBoost
[04:37:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 22.361083269119263 seconds
[04:37:40] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 21.558650732040405 seconds
training LightGBM
LightGBM: 12.915673732757568 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.498551  0.498702
30   0.465616  0.435091  0.435797
45   0.437321  0.404291  0.402613
60   0.416064  0.383384  0.382852
75   0.401602  0.366779  0.366588
90   0.387134  0.356035  0.356626
105  0.376121  0.347044  0.346900
120  0.368930  0.339186  0.340142
135  0.361933  0.332896  0.333221
150  0.357223  0.327741  0.327381
165  0.349977  0.322623  0.322336
180  0.344920  0.318604  0.316594
195  0.339195  0.313570  0.311414

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.499141  0.499510
30   0.466785  0.436483  0.437333
45   0.439002  0.406118  0.404662
60   0.418094  0.385431  0.385206
75   0.403939  0.369090  0.369147
90   0.389707  0.358722  0.359459
105  0.379062  0.349946  0.349918
120  0.372137  0.342284  0.343417
135  0.365405  0.336256  0.336673
150  0.360922  0.331347  0.331072
165  0.353928  0.326432  0.326268
180  0.349107  0.322587  0.320845
195  0.343517  0.317807  0.315849

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.126506  0.118833
f15  0.122935  0.108628  0.105144
f26  0.090022  0.080820  0.083973
f27  0.086085  0.107656  0.071126
f12  0.068082  0.078310  0.059453


{'num_leaves': 256, 'n_train': 1000000, 'max_depth': 10}
training XGBoost
[04:38:16] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 46.45002746582031 seconds
[04:39:02] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 47.13844084739685 seconds
training LightGBM
LightGBM: 22.883901834487915 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.654731  0.654782
15   0.436275  0.409136  0.407353
30   0.364068  0.335276  0.332471
45   0.330131  0.300765  0.301992
60   0.309972  0.284512  0.285799
75   0.294529  0.270522  0.271131
90   0.285495  0.258248  0.257753
105  0.274485  0.247846  0.247697
120  0.267220  0.240443  0.241119
135  0.258687  0.233898  0.232676
150  0.250579  0.228270  0.227312
165  0.245805  0.222656  0.223417
180  0.238242  0.218731  0.219868
195  0.231710  0.215134  0.216105

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.655093  0.655152
15   0.439298  0.412880  0.410991
30   0.369188  0.341609  0.338589
45   0.336710  0.308982  0.309876
60   0.317876  0.294392  0.295135
75   0.303677  0.281850  0.281958
90   0.295721  0.271192  0.270131
105  0.285901  0.262132  0.261600
120  0.279843  0.256325  0.256700
135  0.272573  0.251479  0.249916
150  0.265802  0.247573  0.246271
165  0.262552  0.243432  0.243981
180  0.256215  0.241342  0.242365
195  0.251042  0.239506  0.240504

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110276  0.106002  0.094652
f23  0.109606  0.109734  0.106658
f27  0.092350  0.090317  0.057798
f26  0.078407  0.072730  0.074652
f12  0.066186  0.065171  0.052246


{'num_leaves': 1024, 'n_train': 1000000, 'max_depth': 10}
training XGBoost
[04:40:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 73.41037893295288 seconds
[04:41:29] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 77.43654274940491 seconds
training LightGBM
LightGBM: 27.081772804260254 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.651142  0.651142  0.651270
15   0.383524  0.383524  0.383772
30   0.308016  0.308016  0.307161
45   0.274393  0.274393  0.275278
60   0.258309  0.258309  0.258143
75   0.246340  0.246340  0.244057
90   0.234777  0.234777  0.232616
105  0.225060  0.225060  0.224078
120  0.217585  0.217585  0.217155
135  0.210084  0.210084  0.209402
150  0.200119  0.200119  0.204945
165  0.194310  0.194310  0.197544
180  0.191428  0.191428  0.193443
195  0.186787  0.186787  0.188460

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651907  0.651907  0.652048
15   0.391024  0.391024  0.391356
30   0.320003  0.320003  0.319647
45   0.289681  0.289681  0.290851
60   0.275817  0.275817  0.275987
75   0.265776  0.265776  0.264297
90   0.256561  0.256561  0.255231
105  0.249292  0.249292  0.249357
120  0.244795  0.244795  0.244988
135  0.239420  0.239420  0.240081
150  0.232710  0.232710  0.237818
165  0.229940  0.229940  0.233350
180  0.229551  0.229551  0.231826
195  0.227608  0.227608  0.229374

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         921       921  929
15        887       887  957
30        853       853  845
45        605       605  634
60        606       606  497
75        807       807  628
90        524       524  535
105       340       340  468
120       704       704  580
135       248       248  462
150       422       422  744
165       749       749  691
180       232       232  528
195       567       567  638

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.105729  0.105729  0.104315
f15  0.102879  0.102879  0.094698
f27  0.085082  0.085082  0.057278
f26  0.074980  0.074980  0.070339
f12  0.061103  0.061103  0.051727


{'num_leaves': 32, 'n_train': 1000000, 'max_depth': 15}
training XGBoost
[04:43:18] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 22.3176109790802 seconds
[04:43:40] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 21.447571754455566 seconds
training LightGBM
LightGBM: 12.873150825500488 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.497579  0.498695
30   0.465616  0.433017  0.436759
45   0.437321  0.400551  0.405310
60   0.416064  0.379374  0.384706
75   0.401602  0.367048  0.369787
90   0.387134  0.355086  0.358808
105  0.376121  0.345083  0.347798
120  0.368930  0.337904  0.340338
135  0.361933  0.330417  0.331772
150  0.357223  0.323761  0.324435
165  0.349977  0.317371  0.318875
180  0.344920  0.312428  0.314737
195  0.339195  0.308345  0.310399

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.498277  0.499392
30   0.466785  0.434389  0.438104
45   0.439002  0.402278  0.406981
60   0.418094  0.381363  0.386806
75   0.403939  0.369384  0.372112
90   0.389707  0.357700  0.361414
105  0.379062  0.347979  0.350778
120  0.372137  0.341029  0.343688
135  0.365405  0.333855  0.335382
150  0.360922  0.327532  0.328219
165  0.353928  0.321444  0.322906
180  0.349107  0.316756  0.318998
195  0.343517  0.312857  0.314917

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.127693  0.119828
f15  0.122935  0.116502  0.106557
f26  0.090022  0.078011  0.083026
f27  0.086085  0.098919  0.072917
f12  0.068082  0.082346  0.058643


{'num_leaves': 256, 'n_train': 1000000, 'max_depth': 15}
training XGBoost
[04:44:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 46.18380880355835 seconds
[04:45:02] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 45.24555850028992 seconds
training LightGBM
LightGBM: 22.83167600631714 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.653759  0.653882
15   0.436275  0.397689  0.397984
30   0.364068  0.319342  0.320136
45   0.330131  0.283043  0.284247
60   0.309972  0.265661  0.266184
75   0.294529  0.251078  0.251481
90   0.285495  0.242280  0.241609
105  0.274485  0.234119  0.236488
120  0.267220  0.227768  0.229365
135  0.258687  0.222479  0.225269
150  0.250579  0.218504  0.220956
165  0.245804  0.214100  0.216640
180  0.239562  0.210428  0.211856
195  0.233704  0.206175  0.208866

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.654160  0.654291
15   0.439298  0.401931  0.402092
30   0.369188  0.325920  0.326806
45   0.336710  0.291684  0.292814
60   0.317876  0.276088  0.276493
75   0.303677  0.263207  0.263423
90   0.295721  0.256162  0.255162
105  0.285901  0.249801  0.252053
120  0.279843  0.245363  0.246673
135  0.272573  0.242046  0.244567
150  0.265802  0.240092  0.242143
165  0.262552  0.237629  0.239823
180  0.257501  0.235894  0.236835
195  0.253013  0.233382  0.235682

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110624  0.106874  0.096248
f23  0.110058  0.106224  0.106597
f27  0.091593  0.087996  0.059252
f26  0.078340  0.069725  0.071416
f12  0.067197  0.063833  0.049449


{'num_leaves': 1024, 'n_train': 1000000, 'max_depth': 15}
training XGBoost
[04:46:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 101.02375817298889 seconds
[04:47:54] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 114.0264184474945 seconds
training LightGBM
LightGBM: 37.47494626045227 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650549  0.643973  0.643954
15   0.379917  0.338724  0.339882
30   0.301987  0.258629  0.259099
45   0.263452  0.222105  0.223123
60   0.243268  0.206296  0.203529
75   0.227790  0.192565  0.192006
90   0.212702  0.181020  0.180344
105  0.202582  0.171697  0.169099
120  0.194347  0.164250  0.160174
135  0.185765  0.156942  0.153828
150  0.176819  0.150650  0.147376
165  0.170091  0.144355  0.140949
180  0.164323  0.138118  0.134671
195  0.157533  0.131431  0.129470

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651348  0.644941  0.644960
15   0.388126  0.349592  0.350832
30   0.315416  0.276035  0.276559
45   0.281390  0.245225  0.246499
60   0.264951  0.234128  0.232075
75   0.253319  0.226688  0.226859
90   0.242329  0.221518  0.221547
105  0.237006  0.218643  0.216613
120  0.233330  0.217450  0.213708
135  0.229333  0.216016  0.213342
150  0.224727  0.214817  0.212312
165  0.222586  0.213605  0.211028
180  0.221037  0.212242  0.209915
195  0.218470  0.210152  0.209038

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024       988  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.099805  0.104039  0.097005
f15  0.097814  0.097895  0.089892
f27  0.080228  0.076397  0.054279
f26  0.071959  0.066414  0.063344
f12  0.059452  0.058369  0.051050


{'num_leaves': 4096, 'n_train': 1000000, 'max_depth': 15}
training XGBoost
[04:50:34] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 210.35983872413635 seconds
[04:54:07] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 208.8428671360016 seconds
training LightGBM
LightGBM: 61.72194194793701 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.640997  0.636590  0.636563
15   0.317563  0.291948  0.291205
30   0.229187  0.202548  0.203156
45   0.185212  0.164273  0.164330
60   0.167143  0.148091  0.146720
75   0.152685  0.131793  0.132551
90   0.137441  0.122523  0.122828
105  0.127334  0.112892  0.112503
120  0.114207  0.104450  0.102809
135  0.107067  0.096897  0.095732
150  0.099984  0.090378  0.090255
165  0.094205  0.083945  0.083945
180  0.086768  0.078155  0.077053
195  0.078581  0.071887  0.071942

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.643100  0.639137  0.639141
15   0.340330  0.319891  0.319258
30   0.266388  0.248607  0.249178
45   0.235921  0.225026  0.225182
60   0.225254  0.216929  0.215855
75   0.219214  0.211246  0.211314
90   0.214868  0.209586  0.209260
105  0.212827  0.207766  0.207375
120  0.209304  0.206494  0.205317
135  0.208288  0.205194  0.204242
150  0.207166  0.203853  0.203700
165  0.206298  0.202952  0.202617
180  0.204836  0.202244  0.201940
195  0.203333  0.201211  0.201227

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       1158      1079  1794
75       4096      2594  3990
90       4096      4096  1446
105      1882      3973  4096
120       943      1552  2348
135      4096      1647  3131
150      2023       788  1393
165      1275      2553  3521
180      3169      3298  1186
195      3639      1608  1551

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.092808  0.096417  0.092937
f15  0.090187  0.090334  0.083716
f27  0.071361  0.070850  0.051746
f26  0.063860  0.062841  0.059505
f31  0.058116  0.056992  0.074601


{'num_leaves': 16384, 'n_train': 1000000, 'max_depth': 15}
training XGBoost
[04:59:00] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 245.3964192867279 seconds
[05:03:10] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 243.540598154068 seconds
training LightGBM
LightGBM: 86.2934365272522 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.634418  0.634418  0.634725
15   0.277973  0.277973  0.277781
30   0.187036  0.187036  0.187463
45   0.151796  0.151796  0.150985
60   0.135743  0.135743  0.132441
75   0.126092  0.126092  0.121960
90   0.114368  0.114368  0.114322
105  0.103327  0.103327  0.103726
120  0.096412  0.096412  0.095683
135  0.087375  0.087375  0.088443
150  0.080501  0.080501  0.082415
165  0.073825  0.073825  0.078033
180  0.069124  0.069124  0.071547
195  0.064252  0.064252  0.065848

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.638379  0.638379  0.638410
15   0.317402  0.317402  0.316735
30   0.247397  0.247397  0.247023
45   0.225187  0.225187  0.224376
60   0.216443  0.216443  0.214599
75   0.213225  0.213225  0.211182
90   0.209711  0.209711  0.209292
105  0.206936  0.206936  0.206001
120  0.205851  0.205851  0.205000
135  0.204210  0.204210  0.203953
150  0.203327  0.203327  0.202966
165  0.202215  0.202215  0.202609
180  0.201898  0.201898  0.201778
195  0.201364  0.201364  0.201103

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        9049      9049  8614
15       7866      7866  8478
30       6273      6273  6082
45       3104      3104  3489
60       1795      1795  2702
75       3364      3364  3113
90       2919      2919  1301
105      4011      4011  2011
120      3976      3976  3071
135      1924      1924  4145
150      2826      2826  2749
165      2431      2431  1855
180       873       873  1289
195      3867      3867  3392

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.095375  0.095375  0.093222
f15  0.089815  0.089815  0.084110
f27  0.070618  0.070618  0.052257
f26  0.062409  0.062409  0.059501
f31  0.056224  0.056224  0.073349


{'num_leaves': 32, 'n_train': 1000000, 'max_depth': 20}
training XGBoost
[05:09:08] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 22.3543062210083 seconds
[05:09:30] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 21.601871728897095 seconds
training LightGBM
LightGBM: 13.09153437614441 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.670712  0.668968  0.668840
15   0.519764  0.497579  0.498695
30   0.465616  0.433017  0.436759
45   0.437321  0.400551  0.405310
60   0.416064  0.379374  0.384198
75   0.401602  0.366446  0.368489
90   0.387134  0.356462  0.357139
105  0.376121  0.347640  0.347525
120  0.368930  0.339436  0.340291
135  0.361933  0.331315  0.333814
150  0.357223  0.324844  0.326401
165  0.349977  0.318642  0.319250
180  0.344920  0.313780  0.314687
195  0.339195  0.308742  0.309682

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.670815  0.669090  0.668960
15   0.520467  0.498277  0.499392
30   0.466785  0.434389  0.438104
45   0.439002  0.402278  0.406981
60   0.418094  0.381363  0.386366
75   0.403939  0.368830  0.371027
90   0.389707  0.359072  0.359909
105  0.379062  0.350503  0.350525
120  0.372137  0.342583  0.343529
135  0.365405  0.334745  0.337299
150  0.360922  0.328601  0.330175
165  0.353928  0.322562  0.323401
180  0.349107  0.317854  0.319035
195  0.343517  0.313083  0.314244

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.140107  0.125048  0.119417
f15  0.122935  0.111027  0.105055
f26  0.090022  0.079951  0.084381
f27  0.086085  0.099465  0.072204
f12  0.068082  0.084838  0.059524


{'num_leaves': 256, 'n_train': 1000000, 'max_depth': 20}
training XGBoost
[05:10:06] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 45.206685066223145 seconds
[05:10:51] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 44.159932374954224 seconds
training LightGBM
LightGBM: 23.25420570373535 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.658978  0.653759  0.653882
15   0.436275  0.397949  0.398429
30   0.364068  0.319321  0.319392
45   0.330131  0.280924  0.282460
60   0.309972  0.260308  0.260581
75   0.294529  0.246195  0.246320
90   0.285495  0.238251  0.237399
105  0.274485  0.231892  0.231755
120  0.267220  0.225970  0.226808
135  0.258687  0.221754  0.221183
150  0.250579  0.216947  0.217474
165  0.245804  0.212677  0.213359
180  0.239562  0.207560  0.208842
195  0.233704  0.204132  0.205788

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.659296  0.654160  0.654291
15   0.439298  0.402164  0.402700
30   0.369188  0.326011  0.326226
45   0.336710  0.289500  0.291343
60   0.317876  0.270695  0.271149
75   0.303677  0.258203  0.258529
90   0.295721  0.252180  0.251366
105  0.285901  0.247836  0.247761
120  0.279843  0.243872  0.244766
135  0.272573  0.241625  0.240910
150  0.265802  0.238649  0.239234
165  0.262552  0.236353  0.237079
180  0.257501  0.232988  0.234332
195  0.253013  0.231363  0.233252

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f15  0.110624  0.106380  0.097308
f23  0.110058  0.110898  0.106229
f27  0.091593  0.084986  0.057826
f26  0.078340  0.070899  0.072413
f12  0.067197  0.061171  0.049530


{'num_leaves': 1024, 'n_train': 1000000, 'max_depth': 20}
training XGBoost
[05:12:01] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 99.1895523071289 seconds
[05:13:41] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 101.33355188369751 seconds
training LightGBM
LightGBM: 37.10079741477966 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.650549  0.643458  0.643552
15   0.379917  0.337132  0.336633
30   0.301987  0.254547  0.254079
45   0.263452  0.216717  0.217000
60   0.243268  0.196326  0.196308
75   0.227790  0.183981  0.183190
90   0.212702  0.173867  0.173372
105  0.202536  0.164521  0.165280
120  0.194374  0.156230  0.157161
135  0.185182  0.149129  0.149883
150  0.176199  0.142146  0.142416
165  0.168494  0.135063  0.135690
180  0.161549  0.128477  0.129528
195  0.155590  0.123057  0.123928

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.651348  0.644455  0.644528
15   0.388126  0.348313  0.347765
30   0.315416  0.272545  0.272157
45   0.281390  0.240839  0.241094
60   0.264951  0.226687  0.226532
75   0.253319  0.221760  0.220860
90   0.242329  0.218880  0.218523
105  0.236956  0.216367  0.216658
120  0.233646  0.214229  0.214526
135  0.228747  0.212977  0.213260
150  0.224112  0.211425  0.211312
165  0.221090  0.209543  0.210437
180  0.218330  0.208676  0.209740
195  0.216394  0.208059  0.208931

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.098998  0.103551  0.095200
f15  0.098559  0.098764  0.090630
f27  0.079820  0.074899  0.053327
f26  0.071173  0.063356  0.063990
f12  0.059594  0.056441  0.051201


{'num_leaves': 4096, 'n_train': 1000000, 'max_depth': 20}
training XGBoost
[05:16:08] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 259.80710554122925 seconds
[05:20:32] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 284.9743585586548 seconds
training LightGBM
LightGBM: 87.53588533401489 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.640997  0.633776  0.633688
15   0.317563  0.277907  0.277799
30   0.229187  0.185827  0.185617
45   0.185212  0.143685  0.144285
60   0.157450  0.119812  0.119694
75   0.139900  0.103525  0.102177
90   0.124637  0.089445  0.089191
105  0.109539  0.077772  0.076876
120  0.097830  0.067224  0.065761
135  0.087289  0.059082  0.055118
150  0.078557  0.050006  0.047240
165  0.070313  0.042528  0.040429
180  0.062024  0.035838  0.034773
195  0.056294  0.030475  0.030100

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.643100  0.636476  0.636474
15   0.340330  0.308290  0.308098
30   0.266388  0.237060  0.236783
45   0.235921  0.214238  0.214665
60   0.220722  0.206273  0.205841
75   0.215195  0.203469  0.202815
90   0.211442  0.201209  0.201278
105  0.207278  0.199788  0.199458
120  0.204773  0.198383  0.198546
135  0.203375  0.197834  0.197295
150  0.202547  0.197355  0.197103
165  0.201730  0.197240  0.196934
180  0.201061  0.197419  0.197135
195  0.200473  0.198022  0.197806

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      3702  4096
75       4096      3173  4096
90       4096      2853  4096
105      4096      3091  4096
120      4096      4096  4096
135      2935      4096  2178
150      2664      4096  4096
165      3486      4096  4096
180      4096      4096  4096
195      4096      4096  4096

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.089533  0.093178  0.089484
f15  0.088024  0.089299  0.081605
f27  0.069919  0.066631  0.050692
f26  0.062530  0.061258  0.057823
f31  0.058298  0.057023  0.072854


{'num_leaves': 16384, 'n_train': 1000000, 'max_depth': 20}
training XGBoost
[05:27:16] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 467.28752398490906 seconds
[05:35:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 450.8642303943634 seconds
training LightGBM
LightGBM: 165.2559938430786 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.628454  0.624718  0.624982
15   0.234763  0.215275  0.218048
30   0.129398  0.113289  0.114859
45   0.087908  0.078545  0.078537
60   0.068822  0.063355  0.061882
75   0.060333  0.055343  0.053582
90   0.051742  0.046615  0.045932
105  0.042253  0.038134  0.036320
120  0.034349  0.032529  0.029906
135  0.027040  0.026457  0.024515
150  0.022265  0.021426  0.020348
165  0.018087  0.017612  0.016809
180  0.015168  0.014861  0.014285
195  0.013296  0.012840  0.012517

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.635051  0.632634  0.632499
15   0.300698  0.293388  0.293751
30   0.230998  0.227207  0.227403
45   0.211471  0.210498  0.209952
60   0.204740  0.204962  0.203811
75   0.202836  0.202900  0.201827
90   0.201568  0.201753  0.201150
105  0.200776  0.200924  0.200249
120  0.200840  0.200766  0.200268
135  0.201148  0.201254  0.201068
150  0.202082  0.202106  0.202067
165  0.203223  0.203340  0.203290
180  0.204514  0.204519  0.204771
195  0.205864  0.205975  0.206135

Leaf counts
     EQBIN_dw  EQBIN_lg    LGB
0       16384     16384  16384
15      16384     16384  16384
30      16384     15421  15072
45       7877      8527  11197
60       6504      3679   7064
75       6294      3126   3996
90       4979      7633   7997
105      7148      3918   9154
120      8113      7504   9457
135      5417      7686   7416
150      5395      8448   7330
165      7648      5256   6218
180      4666      6114   3467
195      2240      4386   4872

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f23  0.090659  0.092100  0.090546
f15  0.087683  0.086713  0.082065
f27  0.066662  0.065176  0.050034
f26  0.059875  0.059718  0.056698
f31  0.056090  0.055479  0.070772


{'num_leaves': 32, 'n_train': 2000000, 'max_depth': 5}
training XGBoost
[05:46:40] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 42.246012449264526 seconds
[05:47:22] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 40.35346174240112 seconds
training LightGBM
LightGBM: 22.489187240600586 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.668197  0.668792
15   0.502499  0.502499  0.504351
30   0.458417  0.458417  0.460120
45   0.428591  0.428591  0.431825
60   0.412420  0.412420  0.413065
75   0.397671  0.397671  0.395972
90   0.387534  0.387534  0.383286
105  0.378149  0.378149  0.374027
120  0.372052  0.372052  0.365721
135  0.363631  0.363631  0.359936
150  0.356775  0.356775  0.351934
165  0.351817  0.351817  0.347529
180  0.342262  0.342262  0.339184
195  0.337286  0.337286  0.332808

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.668257  0.668860
15   0.503355  0.503355  0.505316
30   0.459662  0.459662  0.461592
45   0.430273  0.430273  0.433632
60   0.414352  0.414352  0.415190
75   0.399917  0.399917  0.398316
90   0.389928  0.389928  0.385778
105  0.380722  0.380722  0.376646
120  0.374797  0.374797  0.368496
135  0.366580  0.366580  0.362844
150  0.359827  0.359827  0.354928
165  0.354992  0.354992  0.350621
180  0.345515  0.345515  0.342442
195  0.340667  0.340667  0.336205

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         31        31   32
90         27        27   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.130517  0.130517  0.116585
f29  0.094960  0.094960  0.097067
f16  0.086271  0.086271  0.081918
f31  0.080593  0.080593  0.036486
f12  0.069270  0.069270  0.059917


{'num_leaves': 32, 'n_train': 2000000, 'max_depth': 10}
training XGBoost
[05:48:26] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 41.2169713973999 seconds
[05:49:07] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 37.7334680557251 seconds
training LightGBM
LightGBM: 25.70473027229309 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492801  0.492586
30   0.458417  0.435045  0.433973
45   0.428591  0.402957  0.403211
60   0.412332  0.382094  0.382484
75   0.397652  0.370901  0.368490
90   0.387497  0.361233  0.356052
105  0.378310  0.350306  0.347458
120  0.368572  0.339882  0.338753
135  0.360008  0.331246  0.331536
150  0.353769  0.324822  0.325243
165  0.349606  0.319309  0.317694
180  0.344543  0.314639  0.312886
195  0.337779  0.311072  0.307084

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493941  0.493720
30   0.459662  0.436595  0.435456
45   0.430273  0.404880  0.405039
60   0.414270  0.384326  0.384516
75   0.399854  0.373299  0.370750
90   0.389975  0.363858  0.358529
105  0.381044  0.353100  0.350085
120  0.371437  0.342698  0.341536
135  0.362940  0.334214  0.334439
150  0.356809  0.327931  0.328246
165  0.352735  0.322511  0.320871
180  0.347761  0.318004  0.316148
195  0.341143  0.314555  0.310520

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.138336  0.111883
f29  0.096980  0.096677  0.096881
f16  0.087717  0.102263  0.086651
f31  0.074015  0.075692  0.037116
f12  0.066929  0.065681  0.061936


{'num_leaves': 256, 'n_train': 2000000, 'max_depth': 10}
training XGBoost
[05:50:12] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 74.21885967254639 seconds
[05:51:27] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 74.40938472747803 seconds
training LightGBM
LightGBM: 46.75326871871948 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652710  0.651779
15   0.416301  0.395077  0.394060
30   0.351350  0.320231  0.322351
45   0.323185  0.296724  0.296705
60   0.307805  0.279908  0.277630
75   0.297070  0.263889  0.262463
90   0.282135  0.251113  0.252029
105  0.271487  0.238350  0.239573
120  0.262332  0.229551  0.230785
135  0.253706  0.221471  0.222859
150  0.243264  0.215901  0.217705
165  0.236092  0.211969  0.214789
180  0.230552  0.206191  0.209184
195  0.227198  0.201775  0.204043

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.653028  0.652045
15   0.419014  0.398354  0.397242
30   0.355150  0.324895  0.327059
45   0.327888  0.302424  0.302278
60   0.313217  0.286330  0.284091
75   0.303062  0.270972  0.269662
90   0.288764  0.258979  0.259941
105  0.278745  0.247014  0.248217
120  0.270235  0.239049  0.240260
135  0.262297  0.231796  0.233192
150  0.252516  0.227110  0.228815
165  0.246085  0.224040  0.226841
180  0.241248  0.219069  0.222077
195  0.238583  0.215493  0.217705

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.136001  0.099881
f29  0.096434  0.097866  0.087777
f16  0.095221  0.092049  0.078846
f24  0.070382  0.067726  0.128869
f9   0.066337  0.063649  0.074207


{'num_leaves': 1024, 'n_train': 2000000, 'max_depth': 10}
training XGBoost
[05:53:30] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 115.03383469581604 seconds
[05:55:26] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 109.54603481292725 seconds
training LightGBM
LightGBM: 57.794132232666016 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.648192  0.648192  0.647304
15   0.364879  0.364879  0.365586
30   0.291926  0.291926  0.294661
45   0.270327  0.270327  0.265765
60   0.251356  0.251356  0.251843
75   0.239048  0.239048  0.239441
90   0.223576  0.223576  0.222618
105  0.214349  0.214349  0.211009
120  0.205396  0.205396  0.201603
135  0.200692  0.200692  0.194081
150  0.191552  0.191552  0.189724
165  0.183042  0.183042  0.184572
180  0.180105  0.180105  0.179099
195  0.177657  0.177657  0.174406

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648686  0.648686  0.647816
15   0.370408  0.370408  0.370942
30   0.300284  0.300284  0.302599
45   0.280182  0.280182  0.275397
60   0.262590  0.262590  0.262766
75   0.251719  0.251719  0.251635
90   0.237951  0.237951  0.236612
105  0.230147  0.230147  0.226704
120  0.222882  0.222882  0.219129
135  0.219705  0.219705  0.213382
150  0.212423  0.212423  0.210788
165  0.205749  0.205749  0.207208
180  0.204338  0.204338  0.203604
195  0.203393  0.203393  0.200372

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         985       985  983
15        985       985  963
30        858       858  803
45        545       545  933
60        428       428  769
75        841       841  418
90        819       819  694
105       591       591  709
120       486       486  629
135       651       651  394
150       873       873  478
165       817       817  665
180       424       424  743
195       548       548  849

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.131471  0.131471  0.097966
f29  0.097900  0.097900  0.088943
f16  0.088010  0.088010  0.076814
f24  0.072497  0.072497  0.123784
f9   0.062764  0.062764  0.069709


{'num_leaves': 32, 'n_train': 2000000, 'max_depth': 15}
training XGBoost
[05:58:20] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 39.719712257385254 seconds
[05:58:59] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 37.97827363014221 seconds
training LightGBM
LightGBM: 25.54884171485901 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492764  0.491935
30   0.458417  0.432709  0.432188
45   0.428591  0.401036  0.402481
60   0.412332  0.381574  0.381095
75   0.397652  0.368847  0.369144
90   0.387497  0.355976  0.356675
105  0.378310  0.345112  0.347515
120  0.368572  0.336908  0.338233
135  0.360008  0.331494  0.331846
150  0.353769  0.325300  0.323982
165  0.349606  0.317515  0.318516
180  0.344543  0.312189  0.311204
195  0.337779  0.306237  0.307261

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493906  0.493109
30   0.459662  0.434252  0.433647
45   0.430273  0.402868  0.404301
60   0.414270  0.383712  0.383136
75   0.399854  0.371223  0.371385
90   0.389975  0.358468  0.359087
105  0.381044  0.347838  0.350122
120  0.371437  0.339798  0.341065
135  0.362940  0.334504  0.334815
150  0.356809  0.328406  0.327114
165  0.352735  0.320802  0.321812
180  0.347761  0.315648  0.314658
195  0.341143  0.309779  0.310849

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.137166  0.116649
f29  0.096980  0.100548  0.097949
f16  0.087717  0.093916  0.085372
f31  0.074015  0.085031  0.035618
f12  0.066929  0.057137  0.058591


{'num_leaves': 256, 'n_train': 2000000, 'max_depth': 15}
training XGBoost
[06:00:04] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 70.88536262512207 seconds
[06:01:15] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 69.02153515815735 seconds
training LightGBM
LightGBM: 47.17816233634949 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652332  0.651208
15   0.416301  0.389403  0.389860
30   0.351350  0.310204  0.309492
45   0.323185  0.279427  0.281829
60   0.307805  0.257062  0.260335
75   0.297070  0.242686  0.243533
90   0.282135  0.233639  0.232481
105  0.271487  0.226250  0.224319
120  0.262332  0.219441  0.217465
135  0.253706  0.215145  0.212750
150  0.243264  0.210053  0.209232
165  0.236092  0.204692  0.205744
180  0.230552  0.201650  0.201731
195  0.227198  0.198414  0.199107

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.652657  0.651481
15   0.419014  0.392599  0.393096
30   0.355150  0.314945  0.314360
45   0.327888  0.285217  0.287844
60   0.313217  0.263842  0.267147
75   0.303062  0.250386  0.251208
90   0.288764  0.242166  0.241061
105  0.278745  0.235564  0.233799
120  0.270235  0.229626  0.227877
135  0.262297  0.226241  0.224076
150  0.252516  0.222083  0.221437
165  0.246085  0.217644  0.218918
180  0.241248  0.215639  0.215667
195  0.238583  0.213325  0.213959

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.142190  0.099271
f29  0.096434  0.095742  0.087326
f16  0.095221  0.090654  0.078728
f24  0.070382  0.068764  0.128522
f9   0.066337  0.062362  0.072408


{'num_leaves': 1024, 'n_train': 2000000, 'max_depth': 15}
training XGBoost
[06:03:14] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 133.41350269317627 seconds
[06:05:29] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 134.09049820899963 seconds
training LightGBM
LightGBM: 65.3717041015625 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.647957  0.642051  0.641569
15   0.364843  0.329033  0.328001
30   0.291531  0.247037  0.246351
45   0.262601  0.218827  0.219192
60   0.241492  0.201040  0.201291
75   0.223358  0.188844  0.187092
90   0.208667  0.178791  0.177429
105  0.198864  0.172384  0.171602
120  0.191361  0.166199  0.166671
135  0.183881  0.162036  0.160279
150  0.175894  0.156325  0.155653
165  0.170904  0.151755  0.152148
180  0.166972  0.146606  0.148373
195  0.161532  0.142182  0.144454

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648459  0.642706  0.642215
15   0.370401  0.335989  0.335014
30   0.300153  0.257969  0.257184
45   0.273498  0.232734  0.233035
60   0.254403  0.217737  0.217809
75   0.238466  0.208457  0.206466
90   0.225990  0.201775  0.200108
105  0.218446  0.198791  0.197796
120  0.213346  0.195900  0.196189
135  0.208342  0.194933  0.192994
150  0.202814  0.192380  0.191435
165  0.200317  0.190673  0.191106
180  0.198599  0.188419  0.190142
195  0.195623  0.186741  0.189252

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.120410  0.128027  0.093003
f29  0.093475  0.088748  0.085148
f16  0.084261  0.084880  0.075484
f24  0.074033  0.073298  0.122135
f8   0.062958  0.058484  0.089409


{'num_leaves': 4096, 'n_train': 2000000, 'max_depth': 15}
training XGBoost
[06:08:57] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 279.13885021209717 seconds
[06:13:39] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 280.5137050151825 seconds
training LightGBM
LightGBM: 109.89200806617737 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.639568  0.633948  0.633987
15   0.313271  0.282930  0.282593
30   0.233586  0.199557  0.199535
45   0.198225  0.166658  0.168971
60   0.177924  0.150070  0.153832
75   0.156173  0.138522  0.138794
90   0.143805  0.130463  0.129635
105  0.135069  0.122695  0.122155
120  0.126857  0.115850  0.114646
135  0.119711  0.109853  0.108534
150  0.114728  0.103052  0.105042
165  0.109073  0.096128  0.096610
180  0.101888  0.090397  0.091888
195  0.095594  0.084521  0.085023

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.640793  0.635462  0.635566
15   0.326588  0.299185  0.299031
30   0.254553  0.225802  0.226068
45   0.226202  0.201993  0.204156
60   0.211672  0.191832  0.195018
75   0.196742  0.186291  0.186851
90   0.190958  0.184805  0.184355
105  0.188376  0.182554  0.181368
120  0.185476  0.181184  0.180166
135  0.183229  0.179229  0.179015
150  0.182545  0.177351  0.178475
165  0.181263  0.175964  0.176131
180  0.178798  0.174955  0.175711
195  0.177058  0.173734  0.174507

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      4096  2992
75       4096      1622  1513
90       4096      4096  4096
105      4096      3796  2613
120      4023      1021  2377
135      4096      2116  3392
150      1010      3906  2235
165       579      2417  3971
180      4096      4096  4096
195      3970      3196  3201

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.109821  0.112321  0.089391
f29  0.086451  0.084541  0.080327
f16  0.080207  0.078688  0.072006
f24  0.075662  0.074335  0.116479
f8   0.062408  0.061281  0.085817


{'num_leaves': 16384, 'n_train': 2000000, 'max_depth': 15}
training XGBoost
[06:20:36] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 366.86396765708923 seconds
[06:26:48] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 360.0431969165802 seconds
training LightGBM
LightGBM: 149.5535979270935 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.630933  0.630933  0.631172
15   0.262745  0.262745  0.263846
30   0.178629  0.178629  0.179103
45   0.149653  0.149653  0.149717
60   0.137552  0.137552  0.136477
75   0.123648  0.123648  0.123074
90   0.116654  0.116654  0.110975
105  0.105837  0.105837  0.105991
120  0.098793  0.098793  0.099503
135  0.093018  0.093018  0.095964
150  0.086149  0.086149  0.090886
165  0.080972  0.080972  0.082661
180  0.077084  0.077084  0.076227
195  0.070767  0.070767  0.072257

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.633762  0.633762  0.633910
15   0.291556  0.291556  0.291410
30   0.220845  0.220845  0.220471
45   0.200232  0.200232  0.199743
60   0.192587  0.192587  0.191338
75   0.185850  0.185850  0.184878
90   0.183244  0.183244  0.179924
105  0.179003  0.179003  0.178829
120  0.177503  0.177503  0.177191
135  0.176184  0.176184  0.176893
150  0.174451  0.174451  0.176637
165  0.174149  0.174149  0.174373
180  0.173556  0.173556  0.173223
195  0.172083  0.172083  0.172734

Leaf counts
     EQBIN_dw  EQBIN_lg    LGB
0       12370     12370  12024
15      11097     11097  10685
30       6847      6847   7391
45       5307      5307   3805
60       2695      2695   1630
75       3224      3224   5107
90        981       981   5269
105      4507      4507    672
120      1272      1272   3082
135      4200      4200   1167
150      2617      2617   3474
165      3059      3059   1272
180      2061      2061   3562
195      7533      7533    987

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.108302  0.108302  0.089793
f29  0.083409  0.083409  0.079828
f16  0.078193  0.078193  0.071716
f24  0.073979  0.073979  0.113884
f8   0.061198  0.061198  0.085097


{'num_leaves': 32, 'n_train': 2000000, 'max_depth': 20}
training XGBoost
[06:35:57] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 41.31776714324951 seconds
[06:36:39] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 37.389652252197266 seconds
training LightGBM
LightGBM: 25.38156533241272 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.668197  0.667584  0.667479
15   0.502499  0.492764  0.491935
30   0.458417  0.433222  0.432188
45   0.428591  0.401738  0.402477
60   0.412332  0.381896  0.379921
75   0.397652  0.367902  0.366945
90   0.387497  0.356728  0.353551
105  0.378310  0.348882  0.344919
120  0.368572  0.340144  0.338169
135  0.360008  0.332757  0.330754
150  0.353769  0.325746  0.325658
165  0.349606  0.319835  0.320465
180  0.344543  0.315430  0.314185
195  0.337779  0.309952  0.307976

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.668257  0.667658  0.667597
15   0.503355  0.493906  0.493109
30   0.459662  0.434793  0.433647
45   0.430273  0.403679  0.404300
60   0.414270  0.384145  0.382006
75   0.399854  0.370442  0.369270
90   0.389975  0.359480  0.356086
105  0.381044  0.351759  0.347650
120  0.371437  0.343178  0.341063
135  0.362940  0.335944  0.333800
150  0.356809  0.329055  0.328793
165  0.352735  0.323326  0.323691
180  0.347761  0.319031  0.317519
195  0.341143  0.313676  0.311469

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0          32        32   32
15         32        32   32
30         32        32   32
45         32        32   32
60         32        32   32
75         32        32   32
90         32        32   32
105        32        32   32
120        32        32   32
135        32        32   32
150        32        32   32
165        32        32   32
180        32        32   32
195        32        32   32

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.127185  0.139808  0.115819
f29  0.096980  0.094510  0.097201
f16  0.087717  0.088024  0.084202
f31  0.074015  0.082002  0.033879
f12  0.066929  0.066952  0.059828


{'num_leaves': 256, 'n_train': 2000000, 'max_depth': 20}
training XGBoost
[06:37:42] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 70.28561735153198 seconds
[06:38:53] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 68.50220656394958 seconds
training LightGBM
LightGBM: 47.48444986343384 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.656158  0.652332  0.651194
15   0.416301  0.390072  0.389215
30   0.351350  0.307483  0.307969
45   0.323185  0.271729  0.273141
60   0.307805  0.250788  0.253333
75   0.297070  0.239523  0.241645
90   0.282135  0.230279  0.231909
105  0.271487  0.221768  0.222220
120  0.262332  0.216983  0.215063
135  0.253706  0.210671  0.210620
150  0.243264  0.206110  0.206169
165  0.236092  0.201668  0.202626
180  0.230552  0.199470  0.199018
195  0.227198  0.197128  0.194679

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.656404  0.652657  0.651466
15   0.419014  0.393276  0.392438
30   0.355150  0.312305  0.312857
45   0.327888  0.277716  0.279107
60   0.313217  0.257691  0.260192
75   0.303062  0.247327  0.249381
90   0.288764  0.238973  0.240475
105  0.278745  0.231277  0.231628
120  0.270235  0.227369  0.225336
135  0.262297  0.221940  0.221863
150  0.252516  0.218310  0.218331
165  0.246085  0.214776  0.215757
180  0.241248  0.213599  0.213127
195  0.238583  0.212206  0.209731

Leaf counts
     EQBIN_dw  EQBIN_lg  LGB
0         256       256  256
15        256       256  256
30        256       256  256
45        256       256  256
60        256       256  256
75        256       256  256
90        256       256  256
105       256       256  256
120       256       256  256
135       256       256  256
150       256       256  256
165       256       256  256
180       256       256  256
195       256       256  256

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.133665  0.139886  0.097955
f29  0.096434  0.092662  0.085761
f16  0.095221  0.088697  0.081260
f24  0.070382  0.070674  0.126405
f9   0.066337  0.062238  0.074380


{'num_leaves': 1024, 'n_train': 2000000, 'max_depth': 20}
training XGBoost
[06:40:52] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 134.51315784454346 seconds
[06:43:07] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 128.63748335838318 seconds
training LightGBM
LightGBM: 64.70202565193176 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.647957  0.641910  0.641413
15   0.364843  0.327983  0.328675
30   0.291531  0.242923  0.244298
45   0.262601  0.209299  0.209565
60   0.241492  0.189310  0.190855
75   0.223358  0.178215  0.177900
90   0.208667  0.172201  0.172284
105  0.198864  0.166643  0.167586
120  0.191361  0.160857  0.161393
135  0.183881  0.155487  0.156361
150  0.175894  0.151459  0.150934
165  0.170904  0.147283  0.147022
180  0.166730  0.143837  0.142238
195  0.159862  0.140429  0.138765

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.648459  0.642562  0.642060
15   0.370401  0.335102  0.335665
30   0.300153  0.253984  0.255394
45   0.273498  0.223411  0.223878
60   0.254403  0.206357  0.208107
75   0.238466  0.198666  0.198499
90   0.225990  0.196271  0.196741
105  0.218446  0.194467  0.195825
120  0.213346  0.192255  0.193126
135  0.208342  0.190365  0.191197
150  0.202814  0.189819  0.189039
165  0.200317  0.188932  0.188287
180  0.198392  0.188424  0.186693
195  0.193844  0.188016  0.185985

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        1024      1024  1024
15       1024      1024  1024
30       1024      1024  1024
45       1024      1024  1024
60       1024      1024  1024
75       1024      1024  1024
90       1024      1024  1024
105      1024      1024  1024
120      1024      1024  1024
135      1024      1024  1024
150      1024      1024  1024
165      1024      1024  1024
180      1024      1024  1024
195      1024      1024  1024

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.121470  0.126762  0.093182
f29  0.093262  0.091559  0.084571
f16  0.084588  0.084249  0.075069
f24  0.073451  0.072932  0.121235
f8   0.062614  0.060079  0.090615


{'num_leaves': 4096, 'n_train': 2000000, 'max_depth': 20}
training XGBoost
[06:46:29] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 318.8406503200531 seconds
[06:51:52] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 334.1686542034149 seconds
training LightGBM
LightGBM: 128.90645098686218 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.639568  0.632341  0.632336
15   0.313271  0.273735  0.273573
30   0.233586  0.186708  0.185923
45   0.198093  0.152459  0.150712
60   0.173090  0.133472  0.132075
75   0.153095  0.118241  0.118056
90   0.139472  0.107197  0.107507
105  0.130807  0.098607  0.098537
120  0.120023  0.091047  0.090732
135  0.109868  0.084440  0.083136
150  0.102103  0.075567  0.075833
165  0.095141  0.068567  0.068982
180  0.088646  0.062483  0.062604
195  0.082366  0.056444  0.057873

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.640793  0.633997  0.633994
15   0.326588  0.291041  0.290932
30   0.254553  0.214966  0.214197
45   0.226137  0.191327  0.189770
60   0.207948  0.182071  0.181137
75   0.195296  0.177586  0.177271
90   0.188616  0.175777  0.176015
105  0.186630  0.174563  0.174590
120  0.182771  0.173474  0.173725
135  0.179429  0.172978  0.173084
150  0.177807  0.171085  0.171798
165  0.176607  0.169982  0.170425
180  0.175692  0.169322  0.169789
195  0.175199  0.168851  0.169530

Leaf counts
     EQBIN_dw  EQBIN_lg   LGB
0        4096      4096  4096
15       4096      4096  4096
30       4096      4096  4096
45       4096      4096  4096
60       4096      4096  4096
75       4096      4096  4096
90       4096      3821  4096
105      4096      1000  4096
120      4096      1824  4096
135      4096      2148  4096
150      4096      4096  4096
165      3490      4096  3084
180      4096      4096  4096
195      4096      4096  4096

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.106217  0.109633  0.087486
f29  0.084707  0.083104  0.078489
f16  0.078629  0.076426  0.071003
f24  0.077138  0.073446  0.112226
f8   0.062991  0.059580  0.086101


{'num_leaves': 16384, 'n_train': 2000000, 'max_depth': 20}
training XGBoost
[07:00:08] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_dw: 700.1941220760345 seconds
[07:12:00] Tree method is selected to be 'hist', which uses histogram aggregation for faster training. Using custom sequence of updaters: grow_fast_histmaker
EQBIN_lg: 676.2283413410187 seconds
training LightGBM
LightGBM: 274.0921061038971 seconds

binary_logloss train
     EQBIN_dw  EQBIN_lg       LGB
0    0.628583  0.623934  0.624430
15   0.247857  0.220849  0.222108
30   0.152745  0.124646  0.125545
45   0.111355  0.089135  0.089360
60   0.090130  0.076136  0.072841
75   0.076412  0.066157  0.065283
90   0.062584  0.060797  0.056014
105  0.054098  0.050320  0.050482
120  0.047284  0.041752  0.040456
135  0.037107  0.033672  0.033312
150  0.029694  0.027965  0.028257
165  0.024126  0.022936  0.022763
180  0.020502  0.018807  0.018751
195  0.017097  0.015552  0.016000

binary_logloss valid
     EQBIN_dw  EQBIN_lg       LGB
0    0.632183  0.628600  0.628844
15   0.284126  0.267789  0.268099
30   0.209831  0.197196  0.197264
45   0.186327  0.179140  0.179217
60   0.177504  0.173929  0.172937
75   0.174096  0.171244  0.170636
90   0.171125  0.170688  0.169270
105  0.170100  0.168802  0.169124
120  0.169689  0.168383  0.168068
135  0.168941  0.168034  0.167986
150  0.168830  0.168094  0.167956
165  0.169351  0.168509  0.168630
180  0.169909  0.169262  0.169468
195  0.170715  0.170242  0.170356

Leaf counts
     EQBIN_dw  EQBIN_lg    LGB
0       16384     16384  16384
15      16384     16384  16384
30      16384     16384  16384
45       9371     14553  12908
60      16384      4693   7262
75      13524      7358   3678
90      15480     12039   3546
105      7941      6561   4788
120      3015     10691  12463
135     11508      8199   8796
150     10005     12594  15882
165      9296     13774  13907
180      5952      9225   7196
195     11737      8568  10722

Feature importance(gain) sorted by EQBIN_dw
     EQBIN_dw  EQBIN_lg       LGB
f3   0.098749  0.101787  0.085866
f29  0.079558  0.079651  0.076576
f16  0.074222  0.073522  0.069511
f24  0.073957  0.072686  0.108119
f8   0.061899  0.061199  0.083783


                             Time(sec)                        Ratio             
                              EQBIN_dw EQBIN_lg    LGB EQBIN_dw/LGB EQBIN_lg/LGB
n_train max_depth num_leaves                                                    
500000  5         32              12.2     11.9    5.2          2.3          2.3
        10        32              12.5     11.9    6.0          2.1          2.0
                  256             31.1     31.4   10.9          2.8          2.9
                  1024            47.7     46.5   14.0          3.4          3.3
        15        32              12.1     12.1    6.1          2.0          2.0
                  256             31.8     30.7   11.1          2.9          2.8
                  1024            79.1     81.5   21.7          3.7          3.8
                  4096           145.1    143.2   34.8          4.2          4.1
                  16384          156.7    155.5   49.8          3.1          3.1
        20        32              12.5     12.0    6.0          2.1          2.0
                  256             31.6     30.9   11.6          2.7          2.7
                  1024            78.9     83.9   22.4          3.5          3.7
                  4096           209.5    214.0   53.2          3.9          4.0
                  16384          267.9    263.6   88.0          3.0          3.0
1000000 5         32              22.6     22.1   10.8          2.1          2.1
        10        32              22.4     21.6   12.9          1.7          1.7
                  256             46.5     47.1   22.9          2.0          2.1
                  1024            73.4     77.4   27.1          2.7          2.9
        15        32              22.3     21.4   12.9          1.7          1.7
                  256             46.2     45.2   22.8          2.0          2.0
                  1024           101.0    114.0   37.5          2.7          3.0
                  4096           210.4    208.8   61.7          3.4          3.4
                  16384          245.4    243.5   86.3          2.8          2.8
        20        32              22.4     21.6   13.1          1.7          1.7
                  256             45.2     44.2   23.3          1.9          1.9
                  1024            99.2    101.3   37.1          2.7          2.7
                  4096           259.8    285.0   87.5          3.0          3.3
                  16384          467.3    450.9  165.3          2.8          2.7
2000000 5         32              42.2     40.4   22.5          1.9          1.8
        10        32              41.2     37.7   25.7          1.6          1.5
                  256             74.2     74.4   46.8          1.6          1.6
                  1024           115.0    109.5   57.8          2.0          1.9
        15        32              39.7     38.0   25.5          1.6          1.5
                  256             70.9     69.0   47.2          1.5          1.5
                  1024           133.4    134.1   65.4          2.0          2.1
                  4096           279.1    280.5  109.9          2.5          2.6
                  16384          366.9    360.0  149.6          2.5          2.4
        20        32              41.3     37.4   25.4          1.6          1.5
                  256             70.3     68.5   47.5          1.5          1.4
                  1024           134.5    128.6   64.7          2.1          2.0
                  4096           318.8    334.2  128.9          2.5          2.6
                  16384          700.2    676.2  274.1          2.6          2.5

Logloss
                              EQBIN_dw  EQBIN_lg      LGB  EQBIN_lg-LGB
n_train max_depth num_leaves                                           
500000  5         32           0.36296   0.36296  0.36228       0.00067
        10        32           0.36084   0.32989  0.33306      -0.00317
                  256          0.26726   0.25364  0.25515      -0.00151
                  1024         0.24845   0.24845  0.24307       0.00538
        15        32           0.36084   0.32803  0.32541       0.00262
                  256          0.26803   0.25459  0.25560      -0.00101
                  1024         0.23223   0.22722  0.22681       0.00041
                  4096         0.22261   0.22023  0.22158      -0.00135
                  16384        0.22148   0.22148  0.22219      -0.00071
        20        32           0.36084   0.33081  0.33304      -0.00223
                  256          0.26803   0.25180  0.25049       0.00131
                  1024         0.23134   0.22405  0.22303       0.00102
                  4096         0.22044   0.21882  0.21976      -0.00094
                  16384        0.22389   0.22389  0.22326       0.00063
1000000 5         32           0.34270   0.34270  0.34309      -0.00039
        10        32           0.34286   0.31639  0.31487       0.00152
                  256          0.24967   0.23941  0.23956      -0.00015
                  1024         0.22757   0.22757  0.22908      -0.00152
        15        32           0.34286   0.31226  0.31393      -0.00167
                  256          0.25168   0.23304  0.23539      -0.00235
                  1024         0.21827   0.21009  0.20857       0.00153
                  4096         0.20322   0.20123  0.20094       0.00029
                  16384        0.20134   0.20134  0.20092       0.00041
        20        32           0.34286   0.31172  0.31282      -0.00110
                  256          0.25168   0.23121  0.23212      -0.00092
                  1024         0.21609   0.20795  0.20859      -0.00064
                  4096         0.20022   0.19817  0.19797       0.00020
                  16384        0.20619   0.20639  0.20644      -0.00005
2000000 5         32           0.33979   0.33979  0.33423       0.00555
        10        32           0.33893   0.31382  0.30907       0.00474
                  256          0.23744   0.21472  0.21724      -0.00252
                  1024         0.20274   0.20274  0.19960       0.00314
        15        32           0.33893   0.30837  0.30984      -0.00147
                  256          0.23744   0.21310  0.21347      -0.00037
                  1024         0.19503   0.18647  0.18898      -0.00251
                  4096         0.17666   0.17378  0.17419      -0.00040
                  16384        0.17191   0.17191  0.17282      -0.00091
        20        32           0.33893   0.31194  0.31050       0.00144
                  256          0.23744   0.21204  0.20879       0.00325
                  1024         0.19324   0.18807  0.18549       0.00258
                  4096         0.17502   0.16870  0.16935      -0.00064
                  16384        0.17095   0.17057  0.17068      -0.00011

Done: 13129.097624540329 seconds
